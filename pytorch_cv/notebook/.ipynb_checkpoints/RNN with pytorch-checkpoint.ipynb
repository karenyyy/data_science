{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=dsets.MNIST(root=\"./data\",\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=dsets.MNIST(root=\"./data\",\n",
    "                          train=False,\n",
    "                          transform=transforms.ToTensor()) # important: ToTensor() not ToTensor, with the ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img=test_dataset[0][0].numpy().reshape(28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make dataset iterable\n",
    "- total: 60000\n",
    "- batch_size: 100\n",
    "- iterations: 3000\n",
    "    - 1 iter: one minibatch forward and backward pass\n",
    "- epochs\n",
    "    - 1 epoch: running through the whole dataset once\n",
    "    - epochs = $$ iter \\div \\frac{total data}{batchsize}= \\frac{iter}{batches}=3000 \\div \\frac{60000}{100}=5 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter=3000\n",
    "batch_size=100\n",
    "num_epochs=iter/(len(train_dataset)/batch_size)\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create iterable object from training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen=torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check iterability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "isinstance(train_gen, collections.Iterable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do the same for test dataset (shuffle = False for test data !!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen=torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "\n",
    "        self.hidden_dim=hidden_dim\n",
    "\n",
    "        self.layer_dim=layer_dim\n",
    "\n",
    "        self.rnn=nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
    "\n",
    "        self.fc=nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # initialize hidden state with zeros\n",
    "        # (layer_dim, batch_size, hidden_dim)\n",
    "        h0=Variable(torch.zeros(self.layer_dim, inputs.size(0), self.hidden_dim))\n",
    "\n",
    "        # one time step\n",
    "        out, hn=self.rnn(inputs, h0)\n",
    "\n",
    "        # index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100\n",
    "        out=self.fc(out[:, -1, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=28\n",
    "hidden_dim=100\n",
    "layer_dim=2\n",
    "output_dim=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RNNModel(input_dim, hidden_dim, layer_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimizer function\n",
    "$$\\theta = \\theta - \\eta \\cdot \\triangledown_{\\theta}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 28])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 100])\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())[0].shape) # input --> hidden\n",
    "print(list(model.parameters())[2].shape) # input --> hidden bias\n",
    "print(list(model.parameters())[1].shape) # hidden --> hidden\n",
    "print(list(model.parameters())[3].shape) # hidden --> hidden bias\n",
    "print(list(model.parameters())[4].shape) # hidden --> output\n",
    "print(list(model.parameters())[5].shape) # hidden --> output bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 28, 28])\n",
      "Iteration: 500, Loss: 0.27081024646759033, Accurracy: 96.83\n",
      "Iteration: 1000, Loss: 0.05359356850385666, Accurracy: 97.28\n",
      "Iteration: 1500, Loss: 0.015720169991254807, Accurracy: 97.27\n",
      "Iteration: 2000, Loss: 0.06274192780256271, Accurracy: 97.5\n",
      "Iteration: 2500, Loss: 0.018180452287197113, Accurracy: 97.48\n",
      "Iteration: 3000, Loss: 0.06955025345087051, Accurracy: 97.82\n",
      "Iteration: 3500, Loss: 0.08858495950698853, Accurracy: 97.35000000000001\n",
      "Iteration: 4000, Loss: 0.007645632140338421, Accurracy: 97.94\n",
      "Iteration: 4500, Loss: 0.08248483389616013, Accurracy: 97.77\n",
      "Iteration: 5000, Loss: 0.08872094750404358, Accurracy: 97.71\n",
      "Iteration: 5500, Loss: 0.18298599123954773, Accurracy: 94.38\n",
      "Iteration: 6000, Loss: 0.16726553440093994, Accurracy: 97.02\n",
      "Iteration: 6500, Loss: 0.025333702564239502, Accurracy: 97.69\n",
      "Iteration: 7000, Loss: 0.043630946427583694, Accurracy: 97.26\n",
      "Iteration: 7500, Loss: 0.030608592554926872, Accurracy: 98.08\n",
      "Iteration: 8000, Loss: 0.12056589871644974, Accurracy: 97.39999999999999\n",
      "Iteration: 8500, Loss: 0.07613378763198853, Accurracy: 97.92\n",
      "Iteration: 9000, Loss: 0.04361072927713394, Accurracy: 97.97\n",
      "Iteration: 9500, Loss: 0.0869617834687233, Accurracy: 97.98\n"
     ]
    }
   ],
   "source": [
    "seq_dim=28\n",
    "\n",
    "iter=0\n",
    "for epoch in range(int(num_epochs)): # epoches=5\n",
    "    for images, labels in train_gen: # len(train_gen=600)\n",
    "\n",
    "        # convert inputs to Variables\n",
    "        if iter==1:\n",
    "            print(images.size()) # (100,1, 28, 28)\n",
    "            print(images.view(-1, seq_dim, input_dim).size()) # (100, 784)\n",
    "\n",
    "        images=Variable(images.view(-1, seq_dim, input_dim))\n",
    "        labels=Variable(labels)\n",
    "\n",
    "        # clear grad buffers\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # get outputs with inputs\n",
    "        outputs=model(images)\n",
    "\n",
    "        # loss\n",
    "        loss=criterion(outputs, labels)\n",
    "\n",
    "        # backward gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # updating parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # 1 iter: forward + backward pass\n",
    "        iter+=1\n",
    "\n",
    "        if iter % 500==0:\n",
    "            correct=0\n",
    "            total=0\n",
    "            for images, labels in test_gen:\n",
    "                images=Variable(images.view(-1, seq_dim,input_dim))\n",
    "                outputs=model(images)\n",
    "                # images.data.size(): (100, 784)\n",
    "                # outputs.data.size(): (100, 10)\n",
    "                _, predicted=torch.max(outputs.data, 1)\n",
    "\n",
    "                total+=labels.size(0)\n",
    "\n",
    "                correct+=(predicted==labels).sum()\n",
    "            accuracy=correct/total*100\n",
    "            print(\"Iteration: {}, Loss: {}, Accurracy: {}\".format(iter, loss.data[0], accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
