{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model\n",
    "\n",
    "<img src=\"\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=dsets.MNIST(root=\"./data\",\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=dsets.MNIST(root=\"./data\",\n",
    "                          train=False,\n",
    "                          transform=transforms.ToTensor()) # important: ToTensor() not ToTensor, with the ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_img=test_dataset[0][0].numpy().reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0aeb04bcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(show_img, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels\n",
    "test_dataset[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make dataset iterable\n",
    "- total: 60000\n",
    "- batch_size: 100\n",
    "- iterations: 3000\n",
    "    - 1 iter: one minibatch forward and backward pass\n",
    "- epochs\n",
    "    - 1 epoch: running through the whole dataset once\n",
    "    - epochs = $$ iter \\div \\frac{total data}{batchsize}= \\frac{iter}{batches}=3000 \\div \\frac{60000}{100}=5 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter=3000\n",
    "batch_size=100\n",
    "num_epochs=iter/(len(train_dataset)/batch_size)\n",
    "num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create iterable object from training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen=torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check iterability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "isinstance(train_gen, collections.Iterable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do the same for test dataset (shuffle = False for test data !!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen=torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        # inheritance\n",
    "        super(CNNModel,self).__init__()\n",
    "        # conv 1\n",
    "        self.conv1=nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1=nn.ReLU()\n",
    "        # max pool 1\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=2)\n",
    "        # conv 2\n",
    "        self.conv2=nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1,padding=2)\n",
    "        self.relu2=nn.ReLU()\n",
    "        # max pool 2\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # fc1\n",
    "        \n",
    "        self.fc1=nn.Linear(32*7*7, 10)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # conv 1\n",
    "        net=self.conv1(inputs)\n",
    "        net=self.relu1(net)\n",
    "        # max pool1\n",
    "        net=self.maxpool1(net)\n",
    "        # conv 2\n",
    "        net=self.conv2(net)\n",
    "        net=self.relu2(net)\n",
    "        # max pool2\n",
    "        out=self.maxpool2(net)\n",
    "        \n",
    "        # resize\n",
    "        # original size: (100, 32, 7, 7)\n",
    "        # new size: (100, 32*7*7)\n",
    "        out=out.view(out.size(0), -1)\n",
    "        out=self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 5, 5])\n",
      "torch.Size([32])\n",
      "torch.Size([10, 1568])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters())[0].size()) # output channels, filters, kernel height, kernel width\n",
    "print(list(model.parameters())[1].size())\n",
    "print(list(model.parameters())[2].size())\n",
    "print(list(model.parameters())[3].size())\n",
    "print(list(model.parameters())[4].size())\n",
    "print(list(model.parameters())[5].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "Iteration: 500, Loss: 0.03004816547036171, Accurracy: 97.92\n",
      "Iteration: 1000, Loss: 0.11131425201892853, Accurracy: 97.92999999999999\n",
      "Iteration: 1500, Loss: 0.09197033196687698, Accurracy: 97.81\n",
      "Iteration: 2000, Loss: 0.07160643488168716, Accurracy: 98.06\n",
      "Iteration: 2500, Loss: 0.05089489370584488, Accurracy: 98.24000000000001\n",
      "Iteration: 3000, Loss: 0.07023483514785767, Accurracy: 98.25\n"
     ]
    }
   ],
   "source": [
    "iter=0\n",
    "for epoch in range(int(num_epochs)): # epoches=5\n",
    "    for images, labels in train_gen: # len(train_gen=600)\n",
    "        # convert inputs to Variables\n",
    "        if iter==1:\n",
    "            print(images.size()) # (100, 1, 28, 28)\n",
    "        images=Variable(images)\n",
    "        labels=Variable(labels)\n",
    "         \n",
    "        # clear grad buffers\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # get outputs with inputs\n",
    "        outputs=model(images)\n",
    "        \n",
    "        # loss\n",
    "        loss=criterion(outputs, labels)\n",
    "        \n",
    "        # backward gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 1 iter: forward + backward pass\n",
    "        iter+=1\n",
    "        \n",
    "        if iter % 500==0:\n",
    "            correct=0\n",
    "            total=0\n",
    "            for images, labels in test_gen:\n",
    "                images=Variable(images)\n",
    "                outputs=model(images)\n",
    "                # images.data.size(): (100, 784)\n",
    "                # outputs.data.size(): (100, 10)\n",
    "                _, predicted=torch.max(outputs.data, 1)\n",
    "                \n",
    "                total+=labels.size(0)\n",
    "                \n",
    "                correct+=(predicted==labels).sum()\n",
    "            accuracy=correct/total*100\n",
    "            print(\"Iteration: {}, Loss: {}, Accurracy: {}\".format(iter, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## more cnn models in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        # inheritance\n",
    "        super(CNNModel2,self).__init__()\n",
    "        # conv 1\n",
    "        self.conv1=nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1=nn.ReLU()\n",
    "        # max pool 1\n",
    "        self.avgpool1=nn.AvgPool2d(kernel_size=2)\n",
    "        # conv 2\n",
    "        self.conv2=nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1,padding=2)\n",
    "        self.relu2=nn.ReLU()\n",
    "        # max pool 2\n",
    "        self.avgpool2=nn.AvgPool2d(kernel_size=2)\n",
    "        \n",
    "        # fc1\n",
    "        \n",
    "        self.fc1=nn.Linear(32*7*7, 10)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # conv 1\n",
    "        net=self.conv1(inputs)\n",
    "        net=self.relu1(net)\n",
    "        # max pool1\n",
    "        net=self.avgpool1(net)\n",
    "        # conv 2\n",
    "        net=self.conv2(net)\n",
    "        net=self.relu2(net)\n",
    "        # max pool2\n",
    "        out=self.avgpool2(net)\n",
    "        \n",
    "        # resize\n",
    "        # original size: (100, 32, 7, 7)\n",
    "        # new size: (100, 32*7*7)\n",
    "        out=out.view(out.size(0), -1)\n",
    "        out=self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=CNNModel2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01\n",
    "optimizer=torch.optim.SGD(model2.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 5, 5])\n",
      "torch.Size([32])\n",
      "torch.Size([10, 1568])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(list(model2.parameters())[0].size()) # output channels, filters, kernel height, kernel width\n",
    "print(list(model2.parameters())[1].size())\n",
    "print(list(model2.parameters())[2].size())\n",
    "print(list(model2.parameters())[3].size())\n",
    "print(list(model2.parameters())[4].size())\n",
    "print(list(model2.parameters())[5].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "Iteration: 500, Loss: 0.535190999507904, Accurracy: 83.67999999999999\n",
      "Iteration: 1000, Loss: 0.33017414808273315, Accurracy: 88.98\n",
      "Iteration: 1500, Loss: 0.3632943332195282, Accurracy: 90.38000000000001\n",
      "Iteration: 2000, Loss: 0.351043164730072, Accurracy: 91.4\n",
      "Iteration: 2500, Loss: 0.23424170911312103, Accurracy: 92.24\n",
      "Iteration: 3000, Loss: 0.44090530276298523, Accurracy: 93.01\n"
     ]
    }
   ],
   "source": [
    "iter=0\n",
    "for epoch in range(int(num_epochs)): # epoches=5\n",
    "    for images, labels in train_gen: # len(train_gen=600)\n",
    "        # convert inputs to Variables\n",
    "        if iter==1:\n",
    "            print(images.size()) # (100, 1, 28, 28)\n",
    "        images=Variable(images)\n",
    "        labels=Variable(labels)\n",
    "         \n",
    "        # clear grad buffers\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # get outputs with inputs\n",
    "        outputs=model2(images)\n",
    "        \n",
    "        # loss\n",
    "        loss=criterion(outputs, labels)\n",
    "        \n",
    "        # backward gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 1 iter: forward + backward pass\n",
    "        iter+=1\n",
    "        \n",
    "        if iter % 500==0:\n",
    "            correct=0\n",
    "            total=0\n",
    "            for images, labels in test_gen:\n",
    "                images=Variable(images)\n",
    "                outputs=model2(images)\n",
    "                # images.data.size(): (100, 784)\n",
    "                # outputs.data.size(): (100, 10)\n",
    "                _, predicted=torch.max(outputs.data, 1)\n",
    "                \n",
    "                total+=labels.size(0)\n",
    "                \n",
    "                correct+=(predicted==labels).sum()\n",
    "            accuracy=correct/total*100\n",
    "            print(\"Iteration: {}, Loss: {}, Accurracy: {}\".format(iter, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: Avgpooling accuracy < Maxpooling accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### another cnn: with valid padding (means no padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel3(nn.Module):\n",
    "    def __init__(self):\n",
    "        # inheritance\n",
    "        super(CNNModel3,self).__init__()\n",
    "        # conv 1\n",
    "        self.conv1=nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu1=nn.ReLU()\n",
    "        # max pool 1\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=2)\n",
    "        # conv 2\n",
    "        self.conv2=nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1,padding=0)\n",
    "        self.relu2=nn.ReLU()\n",
    "        # max pool 2\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # fc1\n",
    "        # 1. (28-5)/1+1\n",
    "        # 2. 24/2\n",
    "        # 3. (12-5)/1+1\n",
    "        # 4. 8/2\n",
    "        self.fc1=nn.Linear(32*4*4, 10)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # conv 1\n",
    "        net=self.conv1(inputs)\n",
    "        net=self.relu1(net)\n",
    "        # max pool1\n",
    "        net=self.maxpool1(net)\n",
    "        # conv 2\n",
    "        net=self.conv2(net)\n",
    "        net=self.relu2(net)\n",
    "        # max pool2\n",
    "        out=self.maxpool2(net)\n",
    "        \n",
    "        # resize\n",
    "        out=out.view(out.size(0), -1)\n",
    "        out=self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=CNNModel3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01\n",
    "optimizer=torch.optim.SGD(model2.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 5, 5])\n",
      "torch.Size([32])\n",
      "torch.Size([10, 512])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(list(model3.parameters())[0].size()) # output channels, filters, kernel height, kernel width\n",
    "print(list(model3.parameters())[1].size())\n",
    "print(list(model3.parameters())[2].size())\n",
    "print(list(model3.parameters())[3].size())\n",
    "print(list(model3.parameters())[4].size())\n",
    "print(list(model3.parameters())[5].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "Iteration: 500, Loss: 2.310438394546509, Accurracy: 93.01\n",
      "Iteration: 1000, Loss: 2.312199592590332, Accurracy: 93.01\n",
      "Iteration: 1500, Loss: 2.3113796710968018, Accurracy: 93.01\n",
      "Iteration: 2000, Loss: 2.319981336593628, Accurracy: 93.01\n",
      "Iteration: 2500, Loss: 2.306147813796997, Accurracy: 93.01\n",
      "Iteration: 3000, Loss: 2.300149917602539, Accurracy: 93.01\n"
     ]
    }
   ],
   "source": [
    "iter=0\n",
    "for epoch in range(int(num_epochs)): # epoches=5\n",
    "    for images, labels in train_gen: # len(train_gen=600)\n",
    "        # convert inputs to Variables\n",
    "        if iter==1:\n",
    "            print(images.size()) # (100, 1, 28, 28)\n",
    "        images=Variable(images)\n",
    "        labels=Variable(labels)\n",
    "         \n",
    "        # clear grad buffers\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # get outputs with inputs\n",
    "        outputs=model3(images)\n",
    "        \n",
    "        # loss\n",
    "        loss=criterion(outputs, labels)\n",
    "        \n",
    "        # backward gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 1 iter: forward + backward pass\n",
    "        iter+=1\n",
    "        \n",
    "        if iter % 500==0:\n",
    "            correct=0\n",
    "            total=0\n",
    "            for images, labels in test_gen:\n",
    "                images=Variable(images)\n",
    "                outputs=model2(images)\n",
    "                # images.data.size(): (100, 784)\n",
    "                # outputs.data.size(): (100, 10)\n",
    "                _, predicted=torch.max(outputs.data, 1)\n",
    "                \n",
    "                total+=labels.size(0)\n",
    "                \n",
    "                correct+=(predicted==labels).sum()\n",
    "            accuracy=correct/total*100\n",
    "            print(\"Iteration: {}, Loss: {}, Accurracy: {}\".format(iter, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: accuracy between model and model2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
