
## 结构化数据 (using neural net)
由于特征生成(比如 CNN 的卷积层)的本质和能力很复杂，所以深度学习在各种各样的图像、文本和音频数据问题上得到了广泛的应用。

但在实际行业应用方面我们却很少看到这种情况。公司企业的数据库涉及到结构化数据，这些才是塑造了我们的日常生活的领域。

- 定义
	- 在结构化数据中，你可以将行看作是收集到的数据点或观察，将列看作是表示每个观察的单个属性的字段。比如说，来自在线零售商店的数据有表示客户交易事件的列和包含所买商品、数量、价格、时间戳等信息的列。


- 如何将神经网络用于结构化数据任务
	- 实际上，在理论层面上，创建带有任何所需架构的全连接网络都很简单，然后使用「列」作为输入即可。在损失函数经历过一些点积和反向传播之后，我们将得到一个训练好的网络，然后就可以进行预测了

	- 尽管看起来非常简单直接，但在处理结构化数据时，人们往往更偏爱基于树的方法，而不是神经网络


- 对结构化数据和非结构化数据的处理方式是不同的:
	- 非结构化数据虽然是「非常规的」，但我们通常处理的是单位量的单个实体，比如像素、体素、音频频率、雷达反向散射、传感器测量结果等等
	- 而对于结构化数据，我们往往需要处理多种不同的数据类型;这些数据类型分为两大类：数值数据和类别数据

		- 标签/数值编码
		- one-hot 编码。

#### 神经网络的连续性本质限制了它们在类别变量上的应用。因此，用整型数表示类别变量然后就直接应用神经网络，不能得到好的结果


#### 基于树的算法不需要假设类别变量是连续的，因为它们可以按需要进行分支来找到各个状态，但神经网络不是这样的。


### solution:

- #### entity embedding
	- 将离散值映射到多维空间中，其中具有相似函数输出的值彼此靠得更近
	- 在 NLP 领域有非常广泛的应用，其中每个词都可表示为一个向量。__Glove 和 word2vec 是其中两种著名的嵌入方法__
		- 比如说，如果要为一个销售问题将各个省份嵌入到国家这个空间中，那么相似省份的销售就会在这个投射的空间相距更近
	
    - __因为我们不想在我们的类别变量的层次上做任何假设，所以我们将在欧几里得空间中学习到每个类别的更好表示。这个表示很简单，就等于 one-hot 编码与可学习的权重的点积__

![](https://raw.githubusercontent.com/karenyyy/data_science/master/md/images/1.png)

#### Eg:

[Kaggle taxi contest](https://www.kaggle.com/c/pkdd-15-predict-taxi-service-trajectory-i)


为了处理由客户 ID、出租车 ID、日期和时间信息组成的离散的元数据，我们使用该模型为这些信息中的每种信息联合学习了嵌入。这种方法的灵感来自于自然语言建模方法，其中每个词都映射到了一个固定大小的向量空间(这种向量被称为word embedding)

![](https://raw.githubusercontent.com/karenyyy/data_science/master/md/images/2.png)


- 1.初始化一个随机的嵌入矩阵 mxD：
	- m：类别变量的不同层次(星期一、星期二……)的数量
	- D：用于表示的所需的维度，这是一个可以取值 1 到 m-1 的超参数(取 1 就是标签编码，取 m 就是 one-hot 编码)
![]()
- 2.然后，对于神经网络中的每一次前向通过，我们都在该嵌入矩阵中查询一次给定的标签(比如为「dow」查询星期一)，这会得到一个 1xD 的向量
	