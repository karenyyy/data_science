{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8fd18ebe311ab216ff8d9446a8f6b5010a9e1fba"
   },
   "source": [
    "This kernel trains a Variational Autoencoder in Keras with Gaussian input and output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bfd324e0f39675b85e2f14673d29262764c1aac0"
   },
   "source": [
    "Import Keras and other necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karen/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Lambda, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b36a8d510f6130f8b00c64f6ae7fba9f3427f81f"
   },
   "source": [
    "Read data and set train/validation/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "daf551eb-a910-4d3d-82d1-2c1ceffbe221",
    "_uuid": "a36f5f17a310779236b09a94ed67fadcb1313c92"
   },
   "outputs": [],
   "source": [
    "#read the dataset\n",
    "csv = pd.read_csv(\"../data/creditcard.csv\")\n",
    "\n",
    "test_split = 0.3 #portion of data used for testing\n",
    "val_split = 0.2 #portion of training data used for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c56caafd3b4b8493ca73778a24d6b945d8515c5"
   },
   "source": [
    "Prepare training, validation and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "01cf0cc2-5932-4916-bf3c-ffcfbc9c114c",
    "_uuid": "b4d90f3e596bd62ce207eac9276290a240f8bdf0",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.619995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.660004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798279</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.989998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798279 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28      Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.619995      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.690000      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.660004      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.500000      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.989998      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = csv.astype('float32').copy()\n",
    "data.sort_values('Time', inplace=True)\n",
    "\n",
    "data.head()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_test = int(data.shape[0] * (1 - test_split))\n",
    "first_val = int(first_test * (1 - val_split))\n",
    "\n",
    "train = data.iloc[:first_val]\n",
    "val = data.iloc[first_val:first_test]\n",
    "test = data.iloc[first_test:]\n",
    "\n",
    "x_train_df, x_val_df, x_test_df = train.iloc[:, 1:-2], val.iloc[:, 1:-2], test.iloc[:, 1:-2]\n",
    "y_train_df, y_val_df, y_test_df = train.iloc[:, -1], val.iloc[:, -1], test.iloc[:, -1]\n",
    "\n",
    "x_train, x_val, x_test = x_train_df.values, x_val_df.values, x_test_df.values\n",
    "y_train, y_val, y_test = y_train_df.values, y_val_df.values, y_test_df.values\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "x_train, x_val, x_test = scaler.fit_transform(x_train), scaler.fit_transform(x_val), scaler.fit_transform(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4ea7827f403325785f0a726e078d13e6c9a526f5"
   },
   "source": [
    "Build the model and print summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "_cell_guid": "770eb2e9-769d-4b91-b45f-50649491511e",
    "_uuid": "14baa17af3a2f125d3f760534571af214f51634b"
   },
   "outputs": [],
   "source": [
    "hidden_size = 16 #size of the hidden layer in encoder and decoder\n",
    "latent_dim = 2 #number of latent variables to learn\n",
    "\n",
    "input_dim = x_train.shape[1]\n",
    "\n",
    "x = Input(shape=(input_dim,))\n",
    "t = BatchNormalization()(x)\n",
    "t = Dense(hidden_size, activation='tanh' , name='encoder_hidden')(t)\n",
    "t = BatchNormalization()(t)\n",
    "\n",
    "z_mean = Dense(latent_dim, name='z_mean')(t)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(t)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=K.shape(z_mean), mean=0., stddev=1.)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "z = Lambda(sampling, name='z_sampled')([z_mean, z_log_var])\n",
    "#t = BatchNormalization()(z)\n",
    "\n",
    "t = Dense(hidden_size, activation='tanh', name='decoder_hidden')(z)\n",
    "#t = BatchNormalization()(t)\n",
    "\n",
    "decoded_mean = Dense(input_dim, activation=None, name='decoded_mean')(t)\n",
    "\n",
    "vae = Model(x, decoded_mean)\n",
    "\n",
    "def rec_loss(y_true, y_pred):\n",
    "    return K.sum(K.square(y_true - y_pred), axis=-1)\n",
    "\n",
    "def kl_loss(y_true, y_pred):\n",
    "    return - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "\n",
    "def vae_loss(x, decoded_mean):\n",
    "    rec_loss = K.sum(K.square(x - decoded_mean), axis=-1)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return K.mean((rec_loss + kl_loss) / 2)\n",
    "\n",
    "vae.compile(optimizer=Adam(lr=1e-2), loss=vae_loss, metrics=[rec_loss, kl_loss])\n",
    "vae.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "986cf6f9649034e015727b6845a141f03af2bdb3"
   },
   "source": [
    "Train the model with early stopping and a kind of learning rate schedule for the specified number of epochs with the specified batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "_uuid": "2bbe25a6961e252294913a036c11ad68aafcf90f"
   },
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "batch_size = 128\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=10, min_delta=1e-5) #stop training if loss does not decrease with at least 0.00001\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', patience=5, min_delta=1e-5, factor=0.2) #reduce learning rate (divide it by 5 = multiply it by 0.2) if loss does not decrease with at least 0.00001\n",
    "\n",
    "callbacks = [early_stopping, reduce_lr]\n",
    "\n",
    "#collect training data in history object\n",
    "history = vae.fit(x_train, x_train, \n",
    "                  validation_data=(x_val, x_val), \n",
    "                  batch_size=batch_size, epochs=n_epochs, \n",
    "                  callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7ff8ac9002fc5035470e92de7a5fd8fd775b9f22"
   },
   "source": [
    "Plotting training and validation loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_cell_guid": "488e0909-8376-4e10-9126-073c45c0422a",
    "_uuid": "242200ed138247c77abc7debaa04e12ba978f1cb"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 6))\n",
    "ax = fig.gca()\n",
    "ax.plot(history.history['rec_loss']);\n",
    "ax.plot(history.history['val_rec_loss']);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "84dce722240914836f49d38bec4db13e18e132ad"
   },
   "source": [
    "Plotting the learned latent representations for normal and anomalous instances in the specified dataset (training/validation/test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "_cell_guid": "da255d38-33ab-47d9-820d-1698a0e57de9",
    "_uuid": "1b584c09b0881faf4bb5f04b8b1e68e27fd22aa6"
   },
   "outputs": [],
   "source": [
    "x_data = x_train\n",
    "y_data = y_train\n",
    "\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "with_labels = np.concatenate([x_data, np.reshape(y_data, (-1, 1))], axis=1) #concatenate x and y to be able to filter by class\n",
    "\n",
    "normal = with_labels[np.where(with_labels[:, -1] == 0)] #filter normal instances\n",
    "anomalous = with_labels[np.where(with_labels[:, -1] == 1)] #filter anomalous instances\n",
    "\n",
    "normal_encoded = encoder.predict(normal[:, :-1], batch_size=128)\n",
    "anomalous_encoded = encoder.predict(anomalous[:, :-1], batch_size=128)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "ax = fig.gca()\n",
    "\n",
    "#semicolon at the end hides unnecessary output\n",
    "ax.scatter(normal_encoded[:, 0], normal_encoded[:, 1]);\n",
    "ax.scatter(anomalous_encoded[:, 0], anomalous_encoded[:, 1]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d7f755b11f863f43f20d665619362a57728cad0"
   },
   "source": [
    "Apply simple Linear Discriminant Analysis to learned features (the latent representations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "_cell_guid": "8f9658ca-6f31-4046-9c4f-272632e946e0",
    "_uuid": "13ea7fe9d3a974beebebd87093c1fb1712b71d27"
   },
   "outputs": [],
   "source": [
    "with_labels_encoded = encoder.predict(with_labels[:, :-1], batch_size=128)\n",
    "\n",
    "X = with_labels_encoded\n",
    "y = with_labels[:, -1]\n",
    "\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(X, y)\n",
    "\n",
    "pred = clf.predict(X)\n",
    "\n",
    "print(\"AUC(ROC): \" + str(metrics.roc_auc_score(y, pred)))\n",
    "print(\"Precision: \" + str(metrics.precision_score(y, pred)))\n",
    "print(\"Recall: \" + str(metrics.recall_score(y, pred)))\n",
    "print(\"F1 score: \" + str(metrics.f1_score(y, pred)))\n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y, pred).ravel()\n",
    "\n",
    "print(\"False positives: \" + str(fp))\n",
    "print(\"True positives: \" + str(tp))\n",
    "print(\"False negatives: \" + str(fn))\n",
    "print(\"True negateives: \" + str(tn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
