{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingredients for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Source of knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature representation\n",
    "    - problem specific\n",
    "- Unlabeled data?\n",
    "    - case 1: Unsupervised Learning\n",
    "        - go ahead without label \n",
    "            - seq2seq end to end model\n",
    "    - case 2: Supervised Learning\n",
    "        - add label to data by training\n",
    "            - semantic interpretation of (mostly unlabeled images -> IMAGE-CAPTION or untagged texts -> POS)\n",
    "                - mainly the idea of Encoder-Decoder apply here\n",
    "                    - Image-Cap: \n",
    "                        - Encoder (Convolutional NN): image -> feature map\n",
    "                        - Decoder (RNN / LSTM) feature map -> readable sentence\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN (finish later in ML_FROM_SCRATCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(complete later)\n",
    "\n",
    "Data samples are assumed to lie in an n-dim space, eg: euclidean space\n",
    "\n",
    "An instance X is described by feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization can be important __when the varibales are not all measured on the same scale__\n",
    "\n",
    "- 0-1 scaling\n",
    "\n",
    "$$range = max - min$$\n",
    "\n",
    "$$\\frac{(i-min)}{range}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Nearest neightbor Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Learning phase\n",
    "\n",
    "For each training example $(X_p, f(X_p))$, store the sample in memory\n",
    "\n",
    "- Classification Phase\n",
    "\n",
    "Given a query instance $X_p$ identify the $k$ nearest neighbors $X_1, ..., X_k$ of $X_q$\n",
    "\n",
    "Assign $X_q$ as the label of the majority class\n",
    "\n",
    "$$g(X_q) = \\arg \\max_w(\\sum^K_{i=1}\\delta(w, f(x_i))$$ \n",
    "\n",
    "where\n",
    "\n",
    "$$\\delta(a, b) = 1 iff a=b \\text{ and } \\delta(a,b)=1 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance weighted K nearest neighbor classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Learning phase\n",
    "\n",
    "For each training example $(X_p, f(X_p))$, store the sample in memory\n",
    "\n",
    "- Classification Phase\n",
    "\n",
    "Given a query instance $X_p$ identify the $k$ nearest neighbors $X_1, ..., X_k$ of $X_q$\n",
    "\n",
    "$$KNN(X_q) = \\{ X_1, ..., X_q\\}$$\n",
    "\n",
    "__And obtain a weighted note, with each nn getting a vote in favor of its class label that's weighted by the distance to the query__\n",
    "\n",
    "$$w = \\frac{1}{d(X_i, X_q)^2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance Measures - depends on the data representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$d(p, q)$ between two points p and q is a proper distance measure if it satisfies:\n",
    "\n",
    "- Positive definiteness:\n",
    "    - $d(p,q) \\ge 0$ for all p and q and $d(p,q)=0$ only if $p=q$\n",
    "    \n",
    "- Symmetry: $d(p,q) = d(q,p)$ for all p and q\n",
    "- Triangle inequality:\n",
    "    - $d(p,q) \\le d(p,q)+d(q,r)$ for all points p, q and r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $d_1$ and $d_2$ are two document vectors, then\n",
    "\n",
    "$$1- \\cos (d_1, d_2) = 1- \\frac{d_1 \\cdot d_2}{||d_1|| \\cdot ||d_2||}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Euclidean Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Neutral Encoding: does not infer any implicit similarities__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweaking the hyperparameters:\n",
    "\n",
    "__eg: tweaking k in KNN: depend on the density of the available dataset__\n",
    "\n",
    "- grid search (based on the improvement of accuracy / loss convergence)\n",
    "- based on experience of the range of k when it works the best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NN Classifier are conceptually simple\n",
    "- Learn by simply memorizing training examples\n",
    "- The computational effort of learning is low\n",
    "- The storage requirement of learning is high\n",
    "    - need to memorize the examples in the training set\n",
    "- Cost of classifiying new instances can be high\n",
    "    - Use efficient data strutures and algorithms for NN search \n",
    "        - __k-d trees__\n",
    "        - __locality sensitive hashing__\n",
    "- A distance measure needs to be defined over the input space\n",
    "- Performance degrades when there are many irrelevant attributes\n",
    "    - dim reduction? (linear / non-linear)\n",
    "        - PCA\n",
    "        - T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now assume just one independent variable x, and one\n",
    " dependent y\n",
    " \n",
    "- Multiple linear rg assumes an input vector of x\n",
    "- Multivariate 1inear rg assumes an output vector y\n",
    "\n",
    "We will fit the points with a linear hyper-plane\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> How to determine the optimal fit line?\n",
    "\n",
    "- Choose an objective function\n",
    "- For simple linear regression we choose sum squared error (SSE)\n",
    "\n",
    "$$\\sum (d_i - y_i)^2 = \\sum(e_i)^2$$\n",
    "\n",
    "- Thus, find the line with __least squares__\n",
    "\n",
    "- __Bias-Variance Trade-off__\n",
    "![](images/bias-variance-tradeoff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Later after class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### build KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pick up Word2Vec & Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mark down some basic functions in NLTK and Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of RNN for sequential data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Something to think about"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Doc2Vec?](https://medium.com/@mishra.thedeepak/doc2vec-simple-implementation-example-df2afbbfbad5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
