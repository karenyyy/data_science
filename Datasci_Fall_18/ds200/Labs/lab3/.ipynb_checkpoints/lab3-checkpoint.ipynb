{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[tensorflow.js examples](https://js.tensorflow.org/)\n",
    "\n",
    "[source code of teachable machine](https://github.com/googlecreativelab/teachable-machine/tree/master/src/ai)\n",
    "\n",
    "[pretrained model](https://storage.googleapis.com/teachable-machine-squeezenet/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I am a bit curious about how exactly does the Google Teachable Machine works, so I did some digging. As it turns out, the teachable machine is actually a project built with deeplearn.js library.\n",
    "\n",
    "\n",
    "As I see it, it seems like a transfer learning process. The machine feed the webcam images collected into a pre-trained model of SqueezeNet (a light weight neural network with AlexNet level accuracy but with 50x fewer parameters and <0.5MB model size) trained on the ImageNet dataset. So for the webcam images captured, first it does some standard ImageNet pre-processing before inferring through the model. This method returns pre-softmax logits, which then get feed into a KNN (k-nearest neighbors) classifier (with k set to 10) to recognize the ImageNet classes (as we see from the demo to classify the 3 gifs). \n",
    "\n",
    "So with some basic understanding of the model, we can see that actually all the training examples we feed into the teachable machine through webcam first go through a pre-trained SqueezeNet Model to extract some high level features (it's quite deep), like smiles, hands up, hands down, gestures, etc., and then this feature set is feed into the KNN for final Gif classification.\n",
    "\n",
    "\n",
    "Therefore regarding the 3rd question of lab3, of course the machine with more training images captured performs the best, but actually the difference is quite small. If the gathered training images number reaches to a certain level, say 20-30 (because k is set to 10 in the KNN classifier), then the classification result could be pretty accurate, even compared to the machine with more than 100+ images, if the features you displayed in the image are apparent, like hands up and down. The training phrase is actually with the KNN, not the SqueezeNet.\n",
    "\n",
    "![](squeezenet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### javascript source code of SqueezeNet pulled from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    "   * Infer through SqueezeNet, assumes variables have been loaded. This does\n",
    "   * standard ImageNet pre-processing before inferring through the model. This\n",
    "   * method returns named activations as well as pre-softmax logits. The user\n",
    "   * needs to clean up namedActivations after inferring.\n",
    "   *\n",
    "   * @param preprocessedInput preprocessed input Array.\n",
    "   * @return Named activations and the pre-softmax logits.\n",
    "   */\n",
    "  infer(preprocessedInput) {\n",
    "    const namedActivations = {};\n",
    "\n",
    "    const avgpool10 = this.math.scope((keep) => {\n",
    "      const conv1 = this.math.conv2d(\n",
    "          preprocessedInput, this.variables['conv1_W:0'],\n",
    "          this.variables['conv1_b:0'], 2, 0);\n",
    "      const conv1relu = keep(this.math.relu(conv1));\n",
    "\n",
    "      namedActivations['conv_1'] = conv1relu;\n",
    "\n",
    "      const pool1 = keep(this.math.maxPool(conv1relu, 3, 2, 0));\n",
    "      namedActivations['maxpool_1'] = pool1;\n",
    "\n",
    "      const fire2 = keep(this.fireModule(pool1, 2));\n",
    "      namedActivations['fire2'] = fire2;\n",
    "\n",
    "      const fire3 = keep(this.fireModule(fire2, 3));\n",
    "      namedActivations['fire3'] = fire3;\n",
    "\n",
    "      // Because we don't have uneven padding yet, manually pad the ndarray on\n",
    "      // the right.\n",
    "      const fire3Reshape2d =\n",
    "          fire3.as2D(fire3.shape[0], fire3.shape[1] * fire3.shape[2]);\n",
    "      const fire3Sliced2d = this.math.slice2D(\n",
    "          fire3Reshape2d, [0, 0],\n",
    "          [fire3.shape[0] - 1, (fire3.shape[1] - 1) * fire3.shape[2]]);\n",
    "      const fire3Sliced = fire3Sliced2d.as3D(\n",
    "          fire3.shape[0] - 1, fire3.shape[1] - 1, fire3.shape[2]);\n",
    "      const pool2 = keep(this.math.maxPool(fire3Sliced, 3, 2, 0));\n",
    "      namedActivations['maxpool_2'] = pool2;\n",
    "\n",
    "      const fire4 = keep(this.fireModule(pool2, 4));\n",
    "      namedActivations['fire4'] = fire4;\n",
    "\n",
    "      const fire5 = keep(this.fireModule(fire4, 5));\n",
    "      namedActivations['fire5'] = fire5;\n",
    "\n",
    "      const pool3 = keep(this.math.maxPool(fire5, 3, 2, 0));\n",
    "      namedActivations['maxpool_3'] = pool3;\n",
    "\n",
    "      const fire6 = keep(this.fireModule(pool3, 6));\n",
    "      namedActivations['fire6'] = fire6;\n",
    "\n",
    "      const fire7 = keep(this.fireModule(fire6, 7));\n",
    "      namedActivations['fire7'] = fire7;\n",
    "\n",
    "      const fire8 = keep(this.fireModule(fire7, 8));\n",
    "      namedActivations['fire8'] = fire8;\n",
    "\n",
    "      const fire9 = keep(this.fireModule(fire8, 9));\n",
    "      namedActivations['fire9'] = fire9;\n",
    "\n",
    "      const conv10 = keep(this.math.conv2d(\n",
    "          fire9, this.variables['conv10_W:0'],\n",
    "          this.variables['conv10_b:0'], 1, 0));\n",
    "      namedActivations['conv10'] = conv10;\n",
    "\n",
    "      return this.math.avgPool(conv10, conv10.shape[0], 1, 0).as1D();\n",
    "    });\n",
    "\n",
    "    return {namedActivations, logits: avgpool10};\n",
    "  }\n",
    "\n",
    "  fireModule(input, fireId) {\n",
    "    const y1 = this.math.conv2d(\n",
    "        input, this.variables['fire' + fireId + '/squeeze1x1_W:0'],\n",
    "        this.variables['fire' + fireId + '/squeeze1x1_b:0'], 1, 0);\n",
    "    const y2 = this.math.relu(y1);\n",
    "    const left1 = this.math.conv2d(\n",
    "        y2, this.variables['fire' + fireId + '/expand1x1_W:0'],\n",
    "        this.variables['fire' + fireId + '/expand1x1_b:0'], 1, 0);\n",
    "    const left2 = this.math.relu(left1);\n",
    "\n",
    "    const right1 = this.math.conv2d(\n",
    "        y2, this.variables['fire' + fireId + '/expand3x3_W:0'],\n",
    "        this.variables['fire' + fireId + '/expand3x3_b:0'], 1, 1);\n",
    "    const right2 = this.math.relu(right1);\n",
    "\n",
    "    return this.math.concat3D(left2, right2, 2);\n",
    "  }\n",
    "\n",
    "export default SqueezeNet;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the tensorflow version of SqueezeNet model from cs231n Stanford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "NUM_CLASSES = 1000\n",
    "def fire_module(x,inp,sp,e11p,e33p):\n",
    "    with tf.variable_scope(\"fire\"):\n",
    "        with tf.variable_scope(\"squeeze\"):\n",
    "            W = tf.get_variable(\"weights\",shape=[1,1,inp,sp])\n",
    "            b = tf.get_variable(\"bias\",shape=[sp])\n",
    "            s = tf.nn.conv2d(x,W,[1,1,1,1],\"VALID\")+b\n",
    "            s = tf.nn.relu(s)\n",
    "        with tf.variable_scope(\"e11\"):\n",
    "            W = tf.get_variable(\"weights\",shape=[1,1,sp,e11p])\n",
    "            b = tf.get_variable(\"bias\",shape=[e11p])\n",
    "            e11 = tf.nn.conv2d(s,W,[1,1,1,1],\"VALID\")+b\n",
    "            e11 = tf.nn.relu(e11)\n",
    "        with tf.variable_scope(\"e33\"):\n",
    "            W = tf.get_variable(\"weights\",shape=[3,3,sp,e33p])\n",
    "            b = tf.get_variable(\"bias\",shape=[e33p])\n",
    "            e33 = tf.nn.conv2d(s,W,[1,1,1,1],\"SAME\")+b\n",
    "            e33 = tf.nn.relu(e33)\n",
    "        return tf.concat([e11,e33],3)\n",
    "\n",
    "class SqueezeNet(object):\n",
    "    def extract_features(self, input=None, reuse=True):\n",
    "        if input is None:\n",
    "            input = self.image\n",
    "        x = input\n",
    "        layers = []\n",
    "        with tf.variable_scope('features', reuse=reuse):\n",
    "            with tf.variable_scope('layer0'):\n",
    "                W = tf.get_variable(\"weights\",shape=[3,3,3,64])\n",
    "                b = tf.get_variable(\"bias\",shape=[64])\n",
    "                x = tf.nn.conv2d(x,W,[1,2,2,1],\"VALID\")\n",
    "                x = tf.nn.bias_add(x,b)\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer1'):\n",
    "                x = tf.nn.relu(x)\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer2'):\n",
    "                x = tf.nn.max_pool(x,[1,3,3,1],strides=[1,2,2,1],padding='VALID')\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer3'):\n",
    "                x = fire_module(x,64,16,64,64)\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer4'):\n",
    "                x = fire_module(x,128,16,64,64)\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer5'):\n",
    "                x = tf.nn.max_pool(x,[1,3,3,1],strides=[1,2,2,1],padding='VALID')\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer6'):\n",
    "                x = fire_module(x,128,32,128,128)\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer7'):\n",
    "                x = fire_module(x,256,32,128,128)\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer8'):\n",
    "                x = tf.nn.max_pool(x,[1,3,3,1],strides=[1,2,2,1],padding='VALID')\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer9'):\n",
    "                x = fire_module(x,256,48,192,192)\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer10'):\n",
    "                x = fire_module(x,384,48,192,192)\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer11'):\n",
    "                x = fire_module(x,384,64,256,256)\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer12'):\n",
    "                x = fire_module(x,512,64,256,256)\n",
    "                layers.append(x)\n",
    "        return layers\n",
    "\n",
    "    def __init__(self, save_path=None, sess=None):\n",
    "        \"\"\"Create a SqueezeNet model.\n",
    "        Inputs:\n",
    "        - save_path: path to TensorFlow checkpoint\n",
    "        - sess: TensorFlow session\n",
    "        - input: optional input to the model. If None, will use placeholder for input.\n",
    "        \"\"\"\n",
    "        self.image = tf.placeholder('float',shape=[None,None,None,3],name='input_image')\n",
    "        self.labels = tf.placeholder('int32', shape=[None], name='labels')\n",
    "        self.layers = []\n",
    "        x = self.image\n",
    "        self.layers = self.extract_features(x, reuse=False)\n",
    "        self.features = self.layers[-1]\n",
    "        with tf.variable_scope('classifier'):\n",
    "            with tf.variable_scope('layer0'):\n",
    "                x = self.features\n",
    "                self.layers.append(x)\n",
    "            with tf.variable_scope('layer1'):\n",
    "                W = tf.get_variable(\"weights\",shape=[1,1,512,1000])\n",
    "                b = tf.get_variable(\"bias\",shape=[1000])\n",
    "                x = tf.nn.conv2d(x,W,[1,1,1,1],\"VALID\")\n",
    "                x = tf.nn.bias_add(x,b)\n",
    "                self.layers.append(x)\n",
    "            with tf.variable_scope('layer2'):\n",
    "                x = tf.nn.relu(x)\n",
    "                self.layers.append(x)\n",
    "            with tf.variable_scope('layer3'):\n",
    "                x = tf.nn.avg_pool(x,[1,13,13,1],strides=[1,13,13,1],padding='VALID')\n",
    "                self.layers.append(x)\n",
    "        self.classifier = tf.reshape(x,[-1, NUM_CLASSES])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than the parameters like filter numbers, kernel weight, kernel height, we can see that the structure pretty much remain the same. The SqueezeNet used in Teachable Machine does not make much changes. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
