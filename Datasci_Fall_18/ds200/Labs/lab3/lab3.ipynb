{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I am a bit curious about how exactly does the Google Teachable Machine works, so I did some digging. As it turns out, the teachable machine is actually a project built with deeplearn.js library.\n",
    "\n",
    "[tensorflow.js examples](https://js.tensorflow.org/)\n",
    "\n",
    "[source code of teachable machine](https://github.com/googlecreativelab/teachable-machine/tree/master/src/ai)\n",
    "\n",
    "[pretrained model](https://storage.googleapis.com/teachable-machine-squeezenet/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I see it, it seems like the machine feed the webcam images collected into a pretrain model of SqueezeNet (a light weight neural network with AlexNet level accuracy but with 50x fewer parameters and <0.5MB model size) on the ImageNet dataset. And with the high level abstractions extracted, feed it into a KNN (k-nearest neighbors) classifier.\n",
    "\n",
    "The benefit of using the SqueezeNet model instead of feeding the pixel values directly into the KNN classifier is that we use the high level abstractions that the neural network has learned in order to recognize the ImageNet classes. This allows us with very few samples to train a classifier that can recognize things like smiles vs frown, or small movements in your body. This technique is called Transfer Learning.\n",
    "\n",
    "![](squeezenet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "NUM_CLASSES = 1000\n",
    "def fire_module(x,inp,sp,e11p,e33p):\n",
    "    with tf.variable_scope(\"fire\"):\n",
    "        with tf.variable_scope(\"squeeze\"):\n",
    "            W = tf.get_variable(\"weights\",shape=[1,1,inp,sp])\n",
    "            b = tf.get_variable(\"bias\",shape=[sp])\n",
    "            s = tf.nn.conv2d(x,W,[1,1,1,1],\"VALID\")+b\n",
    "            s = tf.nn.relu(s)\n",
    "        with tf.variable_scope(\"e11\"):\n",
    "            W = tf.get_variable(\"weights\",shape=[1,1,sp,e11p])\n",
    "            b = tf.get_variable(\"bias\",shape=[e11p])\n",
    "            e11 = tf.nn.conv2d(s,W,[1,1,1,1],\"VALID\")+b\n",
    "            e11 = tf.nn.relu(e11)\n",
    "        with tf.variable_scope(\"e33\"):\n",
    "            W = tf.get_variable(\"weights\",shape=[3,3,sp,e33p])\n",
    "            b = tf.get_variable(\"bias\",shape=[e33p])\n",
    "            e33 = tf.nn.conv2d(s,W,[1,1,1,1],\"SAME\")+b\n",
    "            e33 = tf.nn.relu(e33)\n",
    "        return tf.concat([e11,e33],3)\n",
    "\n",
    "class SqueezeNet(object):\n",
    "    def extract_features(self, input=None, reuse=True):\n",
    "        if input is None:\n",
    "            input = self.image\n",
    "        x = input\n",
    "        layers = []\n",
    "        with tf.variable_scope('features', reuse=reuse):\n",
    "            with tf.variable_scope('layer0'):\n",
    "                W = tf.get_variable(\"weights\",shape=[3,3,3,64])\n",
    "                b = tf.get_variable(\"bias\",shape=[64])\n",
    "                x = tf.nn.conv2d(x,W,[1,2,2,1],\"VALID\")\n",
    "                x = tf.nn.bias_add(x,b)\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer1'):\n",
    "                x = tf.nn.relu(x)\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer2'):\n",
    "                x = tf.nn.max_pool(x,[1,3,3,1],strides=[1,2,2,1],padding='VALID')\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer3'):\n",
    "                x = fire_module(x,64,16,64,64)\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer4'):\n",
    "                x = fire_module(x,128,16,64,64)\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer5'):\n",
    "                x = tf.nn.max_pool(x,[1,3,3,1],strides=[1,2,2,1],padding='VALID')\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer6'):\n",
    "                x = fire_module(x,128,32,128,128)\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer7'):\n",
    "                x = fire_module(x,256,32,128,128)\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer8'):\n",
    "                x = tf.nn.max_pool(x,[1,3,3,1],strides=[1,2,2,1],padding='VALID')\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer9'):\n",
    "                x = fire_module(x,256,48,192,192)\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer10'):\n",
    "                x = fire_module(x,384,48,192,192)\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer11'):\n",
    "                x = fire_module(x,384,64,256,256)\n",
    "                layers.append(x)\n",
    "            with tf.variable_scope('layer12'):\n",
    "                x = fire_module(x,512,64,256,256)\n",
    "                layers.append(x)\n",
    "        return layers\n",
    "\n",
    "    def __init__(self, save_path=None, sess=None):\n",
    "        \"\"\"Create a SqueezeNet model.\n",
    "        Inputs:\n",
    "        - save_path: path to TensorFlow checkpoint\n",
    "        - sess: TensorFlow session\n",
    "        - input: optional input to the model. If None, will use placeholder for input.\n",
    "        \"\"\"\n",
    "        self.image = tf.placeholder('float',shape=[None,None,None,3],name='input_image')\n",
    "        self.labels = tf.placeholder('int32', shape=[None], name='labels')\n",
    "        self.layers = []\n",
    "        x = self.image\n",
    "        self.layers = self.extract_features(x, reuse=False)\n",
    "        self.features = self.layers[-1]\n",
    "        with tf.variable_scope('classifier'):\n",
    "            with tf.variable_scope('layer0'):\n",
    "                x = self.features\n",
    "                self.layers.append(x)\n",
    "            with tf.variable_scope('layer1'):\n",
    "                W = tf.get_variable(\"weights\",shape=[1,1,512,1000])\n",
    "                b = tf.get_variable(\"bias\",shape=[1000])\n",
    "                x = tf.nn.conv2d(x,W,[1,1,1,1],\"VALID\")\n",
    "                x = tf.nn.bias_add(x,b)\n",
    "                self.layers.append(x)\n",
    "            with tf.variable_scope('layer2'):\n",
    "                x = tf.nn.relu(x)\n",
    "                self.layers.append(x)\n",
    "            with tf.variable_scope('layer3'):\n",
    "                x = tf.nn.avg_pool(x,[1,13,13,1],strides=[1,13,13,1],padding='VALID')\n",
    "                self.layers.append(x)\n",
    "        self.classifier = tf.reshape(x,[-1, NUM_CLASSES])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
