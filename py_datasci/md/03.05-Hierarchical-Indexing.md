
# Hierarchical Indexing

- higher-dimensional data
    - pandas does provide ``Panel`` and ``Panel4D`` objects that natively handle three-dimensional and four-dimensional data  
    - higher-dimensional data can be compactly represented within the familiar one-dimensional ``Series`` and two-dimensional ``DataFrame`` objects.



```python
import pandas as pd
import numpy as np
```


```python
index = [('California', 2000), ('California', 2010),
         ('New York', 2000), ('New York', 2010),
         ('Texas', 2000), ('Texas', 2010)]
populations = [33871648, 37253956,
               18976457, 19378102,
               20851820, 25145561]
pop = pd.Series(populations, index=index)
pop
```




    (California, 2000)    33871648
    (California, 2010)    37253956
    (New York, 2000)      18976457
    (New York, 2010)      19378102
    (Texas, 2000)         20851820
    (Texas, 2010)         25145561
    dtype: int64



With this indexing scheme, we can straightforwardly index or slice the series based on this multiple index:


```python
pop[('California', 2010):('Texas', 2000)]
```




    (California, 2010)    37253956
    (New York, 2000)      18976457
    (New York, 2010)      19378102
    (Texas, 2000)         20851820
    dtype: int64




```python
pop[[i for i in pop.index if i[1] == 2010]]
```




    (California, 2010)    37253956
    (New York, 2010)      19378102
    (Texas, 2010)         25145561
    dtype: int64



### The Better Way: Pandas MultiIndex
Fortunately, Pandas provides a better way.
Our tuple-based indexing is essentially a rudimentary multi-index, and the Pandas ``MultiIndex`` type gives us the type of operations we wish to have.
We can create a multi-index from the tuples as follows:


```python
index = pd.MultiIndex.from_tuples(index)
index
```




   MultiIndex(levels=[['California', 'New York', 'Texas'], [2000, 2010]],
               labels=[[0, 0, 1, 1, 2, 2], [0, 1, 0, 1, 0, 1]])



Notice that the ``MultiIndex`` contains multiple *levels* of indexingâ€“in this case, the state names and the years, as well as multiple *labels* for each data point which encode these levels.

If we re-index our series with this ``MultiIndex``, we see the hierarchical representation of the data:


```python
pop = pop.reindex(index)
pop
```




    California  2000    33871648
                2010    37253956
    New York    2000    18976457
                2010    19378102
    Texas       2000    20851820
                2010    25145561
    dtype: int64



Now to access all data for which the second index is 2010, we can simply use the Pandas slicing notation:


```python
pop[:, 2010]
```




    California    37253956
    New York      19378102
    Texas         25145561
    dtype: int64



### MultiIndex as extra dimension

We could easily have stored the same data using a simple ``DataFrame`` with index and column labels.
Pandas is built with this equivalence in mind. 


The ``unstack()`` method will quickly __convert a multiply indexed ``Series`` into a conventionally indexed ``DataFrame``__:


```python
pop_df = pop.unstack()
pop_df
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2000</th>
      <th>2010</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>California</th>
      <td>33871648</td>
      <td>37253956</td>
    </tr>
    <tr>
      <th>New York</th>
      <td>18976457</td>
      <td>19378102</td>
    </tr>
    <tr>
      <th>Texas</th>
      <td>20851820</td>
      <td>25145561</td>
    </tr>
  </tbody>
</table>
</div>



__Naturally, the ``stack()`` method provides the opposite operation__:


```python
pop_df.stack()
```




    California  2000    33871648
                2010    37253956
    New York    2000    18976457
                2010    19378102
    Texas       2000    20851820
                2010    25145561
    dtype: int64




```python
pop_df = pd.DataFrame({'total': pop,
                       'under18': [9267089, 9284094,
                                   4687374, 4318033,
                                   5906301, 6879014]})
pop_df
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>total</th>
      <th>under18</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">California</th>
      <th>2000</th>
      <td>33871648</td>
      <td>9267089</td>
    </tr>
    <tr>
      <th>2010</th>
      <td>37253956</td>
      <td>9284094</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">New York</th>
      <th>2000</th>
      <td>18976457</td>
      <td>4687374</td>
    </tr>
    <tr>
      <th>2010</th>
      <td>19378102</td>
      <td>4318033</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Texas</th>
      <th>2000</th>
      <td>20851820</td>
      <td>5906301</td>
    </tr>
    <tr>
      <th>2010</th>
      <td>25145561</td>
      <td>6879014</td>
    </tr>
  </tbody>
</table>
</div>




```python
f_u18 = pop_df['under18'] / pop_df['total']
f_u18.unstack()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>2000</th>
      <th>2010</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>California</th>
      <td>0.273594</td>
      <td>0.249211</td>
    </tr>
    <tr>
      <th>New York</th>
      <td>0.247010</td>
      <td>0.222831</td>
    </tr>
    <tr>
      <th>Texas</th>
      <td>0.283251</td>
      <td>0.273568</td>
    </tr>
  </tbody>
</table>
</div>



This allows us to easily and quickly manipulate and explore even high-dimensional data.

## Methods of MultiIndex Creation

The most straightforward way to construct a multiply indexed ``Series`` or ``DataFrame`` is to simply pass a list of two or more index arrays to the constructor. For example:


```python
df = pd.DataFrame(np.random.rand(4, 2),
                  index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]],
                  columns=['data1', 'data2'])
df
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>data1</th>
      <th>data2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">a</th>
      <th>1</th>
      <td>0.681289</td>
      <td>0.681043</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.763471</td>
      <td>0.546326</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">b</th>
      <th>1</th>
      <td>0.637064</td>
      <td>0.238384</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.624997</td>
      <td>0.216924</td>
    </tr>
  </tbody>
</table>
</div>



The work of creating the ``MultiIndex`` is done in the background.

__Similarly, if pass a dictionary with appropriate tuples as keys, Pandas will automatically recognize this and use a ``MultiIndex`` by default__:


```python
data = {('California', 2000): 33871648,
        ('California', 2010): 37253956,
        ('Texas', 2000): 20851820,
        ('Texas', 2010): 25145561,
        ('New York', 2000): 18976457,
        ('New York', 2010): 19378102}
pd.Series(data)
```




    California  2000    33871648
                2010    37253956
    New York    2000    18976457
                2010    19378102
    Texas       2000    20851820
                2010    25145561
    dtype: int64



### Explicit MultiIndex constructors

- from a simple list of arrays giving the index values within each level:


```python
pd.MultiIndex.from_arrays([['a', 'a', 'b', 'b'], [1, 2, 1, 2]])
```




   MultiIndex(levels=[['a', 'b'], [1, 2]],
               labels=[[0, 0, 1, 1], [0, 1, 0, 1]])



- from a list of tuples giving the multiple index values of each point:


```python
pd.MultiIndex.from_tuples([('a', 1), ('a', 2), ('b', 1), ('b', 2)])
```




   MultiIndex(levels=[['a', 'b'], [1, 2]],
               labels=[[0, 0, 1, 1], [0, 1, 0, 1]])



- from a Cartesian product of single indices:


```python
pd.MultiIndex.from_product([['a', 'b'], [1, 2]])
```




   MultiIndex(levels=[['a', 'b'], [1, 2]],
               labels=[[0, 0, 1, 1], [0, 1, 0, 1]])




```python
pd.MultiIndex(levels=[['a', 'b'], [1, 2]],
              labels=[[0, 0, 1, 1], [0, 1, 0, 1]])
```




   MultiIndex(levels=[['a', 'b'], [1, 2]],
               labels=[[0, 0, 1, 1], [0, 1, 0, 1]])



Any of these objects can be passed as the ``index`` argument when creating a ``Series`` or ``Dataframe``, or be passed to the ``reindex`` method of an existing ``Series`` or ``DataFrame``.


```python
pop.index.names = ['state', 'year']
pop
```




    state       year
    California  2000    33871648
                2010    37253956
    New York    2000    18976457
                2010    19378102
    Texas       2000    20851820
                2010    25145561
    dtype: int64



### MultiIndex for columns



```python
# hierarchical indices and columns
index = pd.MultiIndex.from_product([[2013, 2014], [1, 2]],
                                   names=['year', 'visit'])
columns = pd.MultiIndex.from_product([['Bob', 'Guido', 'Sue'], ['HR', 'Temp']],
                                     names=['subject', 'type'])
# mock some data
data = np.round(np.random.randn(4, 6), 1)
data[:, ::2] *= 10
data += 37
# create the DataFrame
health_data = pd.DataFrame(data, index=index, columns=columns)
health_data
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>subject</th>
      <th colspan="2" halign="left">Bob</th>
      <th colspan="2" halign="left">Guido</th>
      <th colspan="2" halign="left">Sue</th>
    </tr>
    <tr>
      <th></th>
      <th>type</th>
      <th>HR</th>
      <th>Temp</th>
      <th>HR</th>
      <th>Temp</th>
      <th>HR</th>
      <th>Temp</th>
    </tr>
    <tr>
      <th>year</th>
      <th>visit</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">2013</th>
      <th>1</th>
      <td>59</td>
      <td>37.4</td>
      <td>35</td>
      <td>35.9</td>
      <td>39</td>
      <td>38.8</td>
    </tr>
    <tr>
      <th>2</th>
      <td>43</td>
      <td>34.8</td>
      <td>31</td>
      <td>36.5</td>
      <td>48</td>
      <td>38.7</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">2014</th>
      <th>1</th>
      <td>56</td>
      <td>36.3</td>
      <td>43</td>
      <td>38.1</td>
      <td>38</td>
      <td>36.5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>42</td>
      <td>38.3</td>
      <td>51</td>
      <td>38.1</td>
      <td>29</td>
      <td>37.8</td>
    </tr>
  </tbody>
</table>
</div>



Here we see where the multi-indexing for both rows and columns can come in *very* handy.
This is fundamentally four-dimensional data, where the dimensions are the subject, the measurement type, the year, and the visit number.
With this in place we can, for example, index the top-level column by the person's name and get a full ``DataFrame`` containing just that person's information:


```python
health_data['Guido']
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>type</th>
      <th>HR</th>
      <th>Temp</th>
    </tr>
    <tr>
      <th>year</th>
      <th>visit</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">2013</th>
      <th>1</th>
      <td>35</td>
      <td>35.9</td>
    </tr>
    <tr>
      <th>2</th>
      <td>31</td>
      <td>36.5</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">2014</th>
      <th>1</th>
      <td>43</td>
      <td>38.1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>51</td>
      <td>38.1</td>
    </tr>
  </tbody>
</table>
</div>



For complicated records containing multiple labeled measurements across multiple times for many subjects (people, countries, cities, etc.) use of hierarchical rows and columns can be extremely convenient!

## Indexing and Slicing a MultiIndex

### Multiply indexed Series

Consider the multiply indexed ``Series`` of state populations:


```python
pop
```




    state       year
    California  2000    33871648
                2010    37253956
    New York    2000    18976457
                2010    19378102
    Texas       2000    20851820
                2010    25145561
    dtype: int64



We can access single elements by indexing with multiple terms:


```python
pop[:, 2000, :]
```




    state
    California    33871648
    New York      18976457
    Texas         20851820
    dtype: int64



The ``MultiIndex`` also supports *partial indexing*, or indexing just one of the levels in the index.
The result is another ``Series``, with the lower-level indices maintained:


```python
pop['California']
```




    year
    2000    33871648
    2010    37253956
    dtype: int64



Partial slicing is available as well, as long as the ``MultiIndex`` is sorted (see discussion in [Sorted and Unsorted Indices](#Sorted-and-unsorted-indices)):


```python
pop.loc['California':'New York']
```




    state       year
    California  2000    33871648
                2010    37253956
    New York    2000    18976457
                2010    19378102
    dtype: int64



Other types of indexing and selection (discussed in [Data Indexing and Selection](03.02-Data-Indexing-and-Selection.ipynb)) work as well; for example, selection based on Boolean masks:


```python
pop[pop > 22000000]
```




    state       year
    California  2000    33871648
                2010    37253956
    Texas       2010    25145561
    dtype: int64



Selection based on fancy indexing also works:


```python
pop.shape
```




   (6,)




```python
pop.iloc[0]
```




   33871648




```python
pop.iloc[0:,]
```




    state       year
    California  2000    33871648
                2010    37253956
    New York    2000    18976457
                2010    19378102
    Texas       2000    20851820
                2010    25145561
    dtype: int64




```python
pop.iloc[1]
```




    37253956




```python
pop.iloc[1:,]
```




    state       year
    California  2010    37253956
    New York    2000    18976457
                2010    19378102
    Texas       2000    20851820
                2010    25145561
    dtype: int64




```python
pop[['California', 'Texas']]
```




    state       year
    California  2000    33871648
                2010    37253956
    Texas       2000    20851820
                2010    25145561
    dtype: int64




```python
health_data.shape
```




    (4, 6)




```python
health_data.iloc[:2, :2]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>subject</th>
      <th colspan="2" halign="left">Bob</th>
    </tr>
    <tr>
      <th></th>
      <th>type</th>
      <th>HR</th>
      <th>Temp</th>
    </tr>
    <tr>
      <th>year</th>
      <th>visit</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">2013</th>
      <th>1</th>
      <td>59</td>
      <td>37.4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>43</td>
      <td>34.8</td>
    </tr>
  </tbody>
</table>
</div>



These indexers provide an array-like view of the underlying two-dimensional data, but each individual index in ``loc`` or ``iloc`` can be passed a tuple of multiple indices. For example:


```python
health_data.loc[:, ('Bob', 'HR')]
```




    year  visit
    2013  1        59
          2        43
    2014  1        56
          2        42
    Name: (Bob, HR), dtype: float64



Working with slices within these index tuples is not especially convenient; trying to create a slice within a tuple will lead to a syntax error:


```python
health_data.loc[(:, 1), (:, 'HR')]
```


      File "<ipython-input-245-8e3cc151e316>", line 1
        health_data.loc[(:, 1), (:, 'HR')]
                         ^
    SyntaxError: invalid syntax



> Solution?

use an ``IndexSlice`` object, which Pandas provides for precisely this situation.


For example:


```python
idx = pd.IndexSlice
health_data.loc[idx[:, 1], idx[:, 'HR']]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>subject</th>
      <th>Bob</th>
      <th>Guido</th>
      <th>Sue</th>
    </tr>
    <tr>
      <th></th>
      <th>type</th>
      <th>HR</th>
      <th>HR</th>
      <th>HR</th>
    </tr>
    <tr>
      <th>year</th>
      <th>visit</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2013</th>
      <th>1</th>
      <td>59</td>
      <td>35</td>
      <td>39</td>
    </tr>
    <tr>
      <th>2014</th>
      <th>1</th>
      <td>56</td>
      <td>43</td>
      <td>38</td>
    </tr>
  </tbody>
</table>
</div>



## Rearranging Multi-Indices



```python
index = pd.MultiIndex.from_product([['a', 'c', 'b'], [1, 2]])
data = pd.Series(np.random.rand(6), index=index)
data.index.names = ['char', 'int']
data
```




    char  int
    a     1      0.768606
          2      0.612794
    c     1      0.438919
          2      0.150284
    b     1      0.466323
          2      0.746574
    dtype: float64



If we try to take a partial slice of this index, it will result in an error:


```python
try:
    data['a':'b']
except KeyError as e:
    print(type(e))
    print(e)
```

    <class 'KeyError'>
    'Key length (1) was greater than MultiIndex lexsort depth (0)'


Although it is not entirely clear from the error message, this is the result of the MultiIndex not being sorted.
For various reasons, partial slices and other similar operations require the levels in the ``MultiIndex`` to be in sorted (i.e., lexographical) order.
Pandas provides a number of convenience routines to perform this type of sorting; examples are the ``sort_index()`` and ``sortlevel()`` methods of the ``DataFrame``.




```python
data = data.sort_index()
data
```




    char  int
    a     1      0.768606
          2      0.612794
    b     1      0.466323
          2      0.746574
    c     1      0.438919
          2      0.150284
    dtype: float64



With the index sorted in this way, partial slicing will work as expected:


```python
data['a':'b']
```




    char  int
    a     1      0.768606
          2      0.612794
    b     1      0.466323
          2      0.746574
    dtype: float64



### Stacking and unstacking indices

As we saw briefly before, it is possible to convert a dataset from a stacked multi-index to a simple two-dimensional representation, optionally specifying the level to use:


```python
pop.unstack()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>year</th>
      <th>2000</th>
      <th>2010</th>
    </tr>
    <tr>
      <th>state</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>California</th>
      <td>33871648</td>
      <td>37253956</td>
    </tr>
    <tr>
      <th>New York</th>
      <td>18976457</td>
      <td>19378102</td>
    </tr>
    <tr>
      <th>Texas</th>
      <td>20851820</td>
      <td>25145561</td>
    </tr>
  </tbody>
</table>
</div>




```python
pop.unstack(level=1)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>year</th>
      <th>2000</th>
      <th>2010</th>
    </tr>
    <tr>
      <th>state</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>California</th>
      <td>33871648</td>
      <td>37253956</td>
    </tr>
    <tr>
      <th>New York</th>
      <td>18976457</td>
      <td>19378102</td>
    </tr>
    <tr>
      <th>Texas</th>
      <td>20851820</td>
      <td>25145561</td>
    </tr>
  </tbody>
</table>
</div>




```python
pop.unstack(level=0)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>state</th>
      <th>California</th>
      <th>New York</th>
      <th>Texas</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2000</th>
      <td>33871648</td>
      <td>18976457</td>
      <td>20851820</td>
    </tr>
    <tr>
      <th>2010</th>
      <td>37253956</td>
      <td>19378102</td>
      <td>25145561</td>
    </tr>
  </tbody>
</table>
</div>



The opposite of ``unstack()`` is ``stack()``, which here can be used to recover the original series:


```python
pop.unstack().stack()
```




    state       year
    California  2000    33871648
                2010    37253956
    New York    2000    18976457
                2010    19378102
    Texas       2000    20851820
                2010    25145561
    dtype: int64



### Index setting and resetting



```python
pop_flat = pop.reset_index(name='population')
pop_flat
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>year</th>
      <th>population</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>California</td>
      <td>2000</td>
      <td>33871648</td>
    </tr>
    <tr>
      <th>1</th>
      <td>California</td>
      <td>2010</td>
      <td>37253956</td>
    </tr>
    <tr>
      <th>2</th>
      <td>New York</td>
      <td>2000</td>
      <td>18976457</td>
    </tr>
    <tr>
      <th>3</th>
      <td>New York</td>
      <td>2010</td>
      <td>19378102</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Texas</td>
      <td>2000</td>
      <td>20851820</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Texas</td>
      <td>2010</td>
      <td>25145561</td>
    </tr>
  </tbody>
</table>
</div>



Often when working with data in the real world, the raw input data looks like this and it's useful to build a ``MultiIndex`` from the column values.
This can be done with the ``set_index`` method of the ``DataFrame``, which returns a multiply indexed ``DataFrame``:


```python
pop_flat.set_index(['state', 'year'])
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>population</th>
    </tr>
    <tr>
      <th>state</th>
      <th>year</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">California</th>
      <th>2000</th>
      <td>33871648</td>
    </tr>
    <tr>
      <th>2010</th>
      <td>37253956</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">New York</th>
      <th>2000</th>
      <td>18976457</td>
    </tr>
    <tr>
      <th>2010</th>
      <td>19378102</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Texas</th>
      <th>2000</th>
      <td>20851820</td>
    </tr>
    <tr>
      <th>2010</th>
      <td>25145561</td>
    </tr>
  </tbody>
</table>
</div>




```python
health_data
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>subject</th>
      <th colspan="2" halign="left">Bob</th>
      <th colspan="2" halign="left">Guido</th>
      <th colspan="2" halign="left">Sue</th>
    </tr>
    <tr>
      <th></th>
      <th>type</th>
      <th>HR</th>
      <th>Temp</th>
      <th>HR</th>
      <th>Temp</th>
      <th>HR</th>
      <th>Temp</th>
    </tr>
    <tr>
      <th>year</th>
      <th>visit</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">2013</th>
      <th>1</th>
      <td>59</td>
      <td>37.4</td>
      <td>35</td>
      <td>35.9</td>
      <td>39</td>
      <td>38.8</td>
    </tr>
    <tr>
      <th>2</th>
      <td>43</td>
      <td>34.8</td>
      <td>31</td>
      <td>36.5</td>
      <td>48</td>
      <td>38.7</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">2014</th>
      <th>1</th>
      <td>56</td>
      <td>36.3</td>
      <td>43</td>
      <td>38.1</td>
      <td>38</td>
      <td>36.5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>42</td>
      <td>38.3</td>
      <td>51</td>
      <td>38.1</td>
      <td>29</td>
      <td>37.8</td>
    </tr>
  </tbody>
</table>
</div>




```python
data_mean = health_data.mean(level='year')
data_mean
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th>subject</th>
      <th colspan="2" halign="left">Bob</th>
      <th colspan="2" halign="left">Guido</th>
      <th colspan="2" halign="left">Sue</th>
    </tr>
    <tr>
      <th>type</th>
      <th>HR</th>
      <th>Temp</th>
      <th>HR</th>
      <th>Temp</th>
      <th>HR</th>
      <th>Temp</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2013</th>
      <td>51</td>
      <td>36.1</td>
      <td>33</td>
      <td>36.2</td>
      <td>43.5</td>
      <td>38.75</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>49</td>
      <td>37.3</td>
      <td>47</td>
      <td>38.1</td>
      <td>33.5</td>
      <td>37.15</td>
    </tr>
  </tbody>
</table>
</div>




```python
data_mean.mean(axis=1, level='type')
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>type</th>
      <th>HR</th>
      <th>Temp</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2013</th>
      <td>42.500000</td>
      <td>37.016667</td>
    </tr>
    <tr>
      <th>2014</th>
      <td>43.166667</td>
      <td>37.516667</td>
    </tr>
  </tbody>
</table>
</div>



# Combining Datasets: Concat and Append



```python
def make_df(cols, ind):
    """Quickly make a DataFrame"""
    data = {c: [str(c) + str(i) for i in ind]
            for c in cols}
    return pd.DataFrame(data, ind)

make_df('ABC', range(3))
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
      <th>C</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A0</td>
      <td>B0</td>
      <td>C0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A1</td>
      <td>B1</td>
      <td>C1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>A2</td>
      <td>B2</td>
      <td>C2</td>
    </tr>
  </tbody>
</table>
</div>




```python
x = [1, 2, 3]
y = [4, 5, 6]
z = [7, 8, 9]
np.concatenate([x, y, z])
```




    array([1, 2, 3, 4, 5, 6, 7, 8, 9])




```python
x = [[1, 2],
     [3, 4]]
np.concatenate([x, x], axis=1)
```




    array([[1, 2, 1, 2],
           [3, 4, 3, 4]])



## Simple Concatenation with ``pd.concat``

Pandas has a function, ``pd.concat()``, which has a similar syntax to ``np.concatenate`` but contains a number of options that we'll discuss momentarily:

```python
# Signature in Pandas v0.18
pd.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False,
          keys=None, levels=None, names=None, verify_integrity=False,
          copy=True)
```

``pd.concat()`` can be used for a simple concatenation of ``Series`` or ``DataFrame`` objects, just as ``np.concatenate()`` can be used for simple concatenations of arrays:


```python
ser1 = pd.Series(['A', 'B', 'C'], index=[1, 2, 3])
ser2 = pd.Series(['D', 'E', 'F'], index=[4, 5, 6])
pd.concat([ser1, ser2])
```




    1    A
    2    B
    3    C
    4    D
    5    E
    6    F
    dtype: object



It also works to concatenate higher-dimensional objects, such as ``DataFrame``s:


```python
df1 = make_df('AB', [1, 2])
df2 = make_df('AB', [3, 4])
df1
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>A1</td>
      <td>B1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>A2</td>
      <td>B2</td>
    </tr>
  </tbody>
</table>
</div>




```python
df2
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3</th>
      <td>A3</td>
      <td>B3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>A4</td>
      <td>B4</td>
    </tr>
  </tbody>
</table>
</div>




```python
df1.append(df2)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>A1</td>
      <td>B1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>A2</td>
      <td>B2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A3</td>
      <td>B3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>A4</td>
      <td>B4</td>
    </tr>
  </tbody>
</table>
</div>




```python
pd.concat([df1, df2], axis=0)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>A1</td>
      <td>B1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>A2</td>
      <td>B2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A3</td>
      <td>B3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>A4</td>
      <td>B4</td>
    </tr>
  </tbody>
</table>
</div>




```python
pd.concat([df1,df2], axis=1)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
      <th>A</th>
      <th>B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>A1</td>
      <td>B1</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>A2</td>
      <td>B2</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>A3</td>
      <td>B3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>A4</td>
      <td>B4</td>
    </tr>
  </tbody>
</table>
</div>



By default, the concatenation takes place row-wise within the ``DataFrame`` (i.e., ``axis=0``).
Like ``np.concatenate``, ``pd.concat`` allows specification of an axis along which concatenation will take place.
Consider the following example:


```python
df3 = make_df('AB', [0, 1])
df4 = make_df('CD', [0, 1])
df3
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A0</td>
      <td>B0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A1</td>
      <td>B1</td>
    </tr>
  </tbody>
</table>
</div>




```python
df4
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>C</th>
      <th>D</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>C0</td>
      <td>D0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>C1</td>
      <td>D1</td>
    </tr>
  </tbody>
</table>
</div>




```python
pd.concat([df3, df4], axis=0)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
      <th>C</th>
      <th>D</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A0</td>
      <td>B0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A1</td>
      <td>B1</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>0</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>C0</td>
      <td>D0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>C1</td>
      <td>D1</td>
    </tr>
  </tbody>
</table>
</div>




```python
pd.concat([df3, df4], axis=1)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
      <th>C</th>
      <th>D</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A0</td>
      <td>B0</td>
      <td>C0</td>
      <td>D0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A1</td>
      <td>B1</td>
      <td>C1</td>
      <td>D1</td>
    </tr>
  </tbody>
</table>
</div>




```python
x = make_df('AB', [0, 1])
y = make_df('AB', [2, 3])
pd.concat([x, y], ignore_index=True)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>A0</td>
      <td>B0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A1</td>
      <td>B1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>A2</td>
      <td>B2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A3</td>
      <td>B3</td>
    </tr>
  </tbody>
</table>
</div>



#### Adding MultiIndex keys

Another option is to use the ``keys`` option to specify a label for the data sources; the result will be a hierarchically indexed series containing the data:


```python
pd.concat([x, y], keys=['x', 'y'])
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>A</th>
      <th>B</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">x</th>
      <th>0</th>
      <td>A0</td>
      <td>B0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>A1</td>
      <td>B1</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">y</th>
      <th>2</th>
      <td>A2</td>
      <td>B2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A3</td>
      <td>B3</td>
    </tr>
  </tbody>
</table>
</div>




```python
df5 = make_df('ABC', [1, 2])
df6 = make_df('BCD', [3, 4])
```

By default, the entries for which no data is available are filled with NA values.
To change this, we can specify one of several options for the ``join`` and ``join_axes`` parameters of the concatenate function.
By default, the join is a union of the input columns (``join='outer'``), but we can change this to an intersection of the columns using ``join='inner'``:


```python
pd.concat([df5, df6], join='inner')
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>B</th>
      <th>C</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>B1</td>
      <td>C1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>B2</td>
      <td>C2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>B3</td>
      <td>C3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>B4</td>
      <td>C4</td>
    </tr>
  </tbody>
</table>
</div>



Another option is to directly specify the index of the remaininig colums using the ``join_axes`` argument, which takes a list of index objects.
Here we'll specify that the returned columns should be the same as those of the first input:


```python
pd.concat([df5, df6], join_axes=[df5.columns])
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>B</th>
      <th>C</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>A1</td>
      <td>B1</td>
      <td>C1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>A2</td>
      <td>B2</td>
      <td>C2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>NaN</td>
      <td>B3</td>
      <td>C3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>NaN</td>
      <td>B4</td>
      <td>C4</td>
    </tr>
  </tbody>
</table>
</div>



# Combining Datasets: Merge and Join



## Categories of Joins

The ``pd.merge()`` function implements a number of types of joins: the *one-to-one*, *many-to-one*, and *many-to-many* joins.
All three types of joins are accessed via an identical call to the ``pd.merge()`` interface; the type of join performed depends on the form of the input data.

### One-to-one joins

Perhaps the simplest type of merge expresion is the one-to-one join, which is in many ways very similar to the column-wise concatenation.

for example:


```python
df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],
                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})
df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],
                    'hire_date': [2004, 2008, 2012, 2014]})
df1
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>employee</th>
      <th>group</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bob</td>
      <td>Accounting</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Jake</td>
      <td>Engineering</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Lisa</td>
      <td>Engineering</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sue</td>
      <td>HR</td>
    </tr>
  </tbody>
</table>
</div>




```python
df2
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>employee</th>
      <th>hire_date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Lisa</td>
      <td>2004</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Bob</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Jake</td>
      <td>2012</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sue</td>
      <td>2014</td>
    </tr>
  </tbody>
</table>
</div>



To combine this information into a single ``DataFrame``, we can use the ``pd.merge()`` function:


```python
df3 = pd.merge(df1, df2)
df3
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>employee</th>
      <th>group</th>
      <th>hire_date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bob</td>
      <td>Accounting</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Jake</td>
      <td>Engineering</td>
      <td>2012</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Lisa</td>
      <td>Engineering</td>
      <td>2004</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sue</td>
      <td>HR</td>
      <td>2014</td>
    </tr>
  </tbody>
</table>
</div>



### Many-to-one joins

Many-to-one joins are joins in which one of the two key columns contains duplicate entries.
For the many-to-one case, the resulting ``DataFrame`` will preserve those duplicate entries as appropriate.
Consider the following example of a many-to-one join:


```python
df4 = pd.DataFrame({'group': ['Accounting', 'Engineering', 'HR'],
                    'supervisor': ['Carly', 'Guido', 'Steve']})
df4
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>group</th>
      <th>supervisor</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Accounting</td>
      <td>Carly</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Engineering</td>
      <td>Guido</td>
    </tr>
    <tr>
      <th>2</th>
      <td>HR</td>
      <td>Steve</td>
    </tr>
  </tbody>
</table>
</div>




```python
df4=pd.merge(df3, df4)
df4
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>employee</th>
      <th>group</th>
      <th>hire_date</th>
      <th>supervisor</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bob</td>
      <td>Accounting</td>
      <td>2008</td>
      <td>Carly</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Jake</td>
      <td>Engineering</td>
      <td>2012</td>
      <td>Guido</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Lisa</td>
      <td>Engineering</td>
      <td>2004</td>
      <td>Guido</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sue</td>
      <td>HR</td>
      <td>2014</td>
      <td>Steve</td>
    </tr>
  </tbody>
</table>
</div>



### Many-to-many joins

Many-to-many joins are a bit confusing conceptually, but are nevertheless well defined.
If the key column in both the left and right array contains duplicates, then the result is a many-to-many merge.
This will be perhaps most clear with a concrete example.
Consider the following, where we have a ``DataFrame`` showing one or more skills associated with a particular group.
By performing a many-to-many join, we can recover the skills associated with any individual person:


```python
df5 = pd.DataFrame({'group': ['Accounting', 'Accounting',
                              'Engineering', 'Engineering', 'HR', 'HR'],
                    'skills': ['math', 'spreadsheets', 'coding', 'linux',
                               'spreadsheets', 'organization']})
df5
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>group</th>
      <th>skills</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Accounting</td>
      <td>math</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Accounting</td>
      <td>spreadsheets</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Engineering</td>
      <td>coding</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Engineering</td>
      <td>linux</td>
    </tr>
    <tr>
      <th>4</th>
      <td>HR</td>
      <td>spreadsheets</td>
    </tr>
    <tr>
      <th>5</th>
      <td>HR</td>
      <td>organization</td>
    </tr>
  </tbody>
</table>
</div>




```python
pd.merge(df4, df5)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>employee</th>
      <th>group</th>
      <th>hire_date</th>
      <th>supervisor</th>
      <th>skills</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bob</td>
      <td>Accounting</td>
      <td>2008</td>
      <td>Carly</td>
      <td>math</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Bob</td>
      <td>Accounting</td>
      <td>2008</td>
      <td>Carly</td>
      <td>spreadsheets</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Jake</td>
      <td>Engineering</td>
      <td>2012</td>
      <td>Guido</td>
      <td>coding</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Jake</td>
      <td>Engineering</td>
      <td>2012</td>
      <td>Guido</td>
      <td>linux</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Lisa</td>
      <td>Engineering</td>
      <td>2004</td>
      <td>Guido</td>
      <td>coding</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Lisa</td>
      <td>Engineering</td>
      <td>2004</td>
      <td>Guido</td>
      <td>linux</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Sue</td>
      <td>HR</td>
      <td>2014</td>
      <td>Steve</td>
      <td>spreadsheets</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Sue</td>
      <td>HR</td>
      <td>2014</td>
      <td>Steve</td>
      <td>organization</td>
    </tr>
  </tbody>
</table>
</div>



> What if the data is not clean as practiced?

## Specification of the Merge Key

### The ``on`` keyword


### The ``left_on`` and ``right_on`` keywords



```python
df3 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],
                    'salary': [70000, 80000, 120000, 90000]})
pd.merge(df1, df3, on="employee")
```


    ---------------------------------------------------------------------------

    KeyError                                  Traceback (most recent call last)

    <ipython-input-120-ea3f9cad185b> in <module>()
          1 df3 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],
          2                     'salary': [70000, 80000, 120000, 90000]})
    ----> 3 pd.merge(df1, df3, on="employee")
    

    /usr/local/lib/python3.5/dist-packages/pandas/tools/merge.py in merge(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)
         32                          right_on=right_on, left_index=left_index,
         33                          right_index=right_index, sort=sort, suffixes=suffixes,
    ---> 34                          copy=copy, indicator=indicator)
         35     return op.get_result()
         36 if __debug__:


    /usr/local/lib/python3.5/dist-packages/pandas/tools/merge.py in __init__(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator)
        188         (self.left_join_keys,
        189          self.right_join_keys,
    --> 190          self.join_names) = self._get_merge_keys()
        191 
        192     def get_result(self):


    /usr/local/lib/python3.5/dist-packages/pandas/tools/merge.py in _get_merge_keys(self)
        401                 else:
        402                     if not is_rkey(rk):
    --> 403                         right_keys.append(right[rk]._values)
        404                         if lk == rk:
        405                             # avoid key upcast in corner case (length-0)


    /usr/local/lib/python3.5/dist-packages/pandas/core/frame.py in __getitem__(self, key)
       1967             return self._getitem_multilevel(key)
       1968         else:
    -> 1969             return self._getitem_column(key)
       1970 
       1971     def _getitem_column(self, key):


    /usr/local/lib/python3.5/dist-packages/pandas/core/frame.py in _getitem_column(self, key)
       1974         # get column
       1975         if self.columns.is_unique:
    -> 1976             return self._get_item_cache(key)
       1977 
       1978         # duplicate columns & possible reduce dimensionality


    /usr/local/lib/python3.5/dist-packages/pandas/core/generic.py in _get_item_cache(self, item)
       1089         res = cache.get(item)
       1090         if res is None:
    -> 1091             values = self._data.get(item)
       1092             res = self._box_item_values(item, values)
       1093             cache[item] = res


    /usr/local/lib/python3.5/dist-packages/pandas/core/internals.py in get(self, item, fastpath)
       3209 
       3210             if not isnull(item):
    -> 3211                 loc = self.items.get_loc(item)
       3212             else:
       3213                 indexer = np.arange(len(self.items))[isnull(self.items)]


    /usr/local/lib/python3.5/dist-packages/pandas/core/index.py in get_loc(self, key, method, tolerance)
       1757                                  'backfill or nearest lookups')
       1758             key = _values_from_object(key)
    -> 1759             return self._engine.get_loc(key)
       1760 
       1761         indexer = self.get_indexer([key], method=method,


    pandas/index.pyx in pandas.index.IndexEngine.get_loc (pandas/index.c:3979)()


    pandas/index.pyx in pandas.index.IndexEngine.get_loc (pandas/index.c:3843)()


    pandas/hashtable.pyx in pandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12265)()


    pandas/hashtable.pyx in pandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12216)()


    KeyError: 'employee'



```python
pd.merge(df1, df3, left_on="employee", right_on="name")
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>employee</th>
      <th>group</th>
      <th>name</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bob</td>
      <td>Accounting</td>
      <td>Bob</td>
      <td>70000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Jake</td>
      <td>Engineering</td>
      <td>Jake</td>
      <td>80000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Lisa</td>
      <td>Engineering</td>
      <td>Lisa</td>
      <td>120000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sue</td>
      <td>HR</td>
      <td>Sue</td>
      <td>90000</td>
    </tr>
  </tbody>
</table>
</div>



The result has a redundant column that we can drop if desiredâ€“for example, by using the ``drop()`` method of ``DataFrame``s:


```python
pd.merge(df1, df3, left_on="employee", right_on="name").drop('name', axis=1)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>employee</th>
      <th>group</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bob</td>
      <td>Accounting</td>
      <td>70000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Jake</td>
      <td>Engineering</td>
      <td>80000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Lisa</td>
      <td>Engineering</td>
      <td>120000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sue</td>
      <td>HR</td>
      <td>90000</td>
    </tr>
  </tbody>
</table>
</div>



### The ``left_index`` and ``right_index`` keywords

Sometimes, rather than merging on a column, you would instead like to merge on an index.
For example, your data might look like this:


```python
df1a = df1.set_index('employee')
df2a = df2.set_index('employee')
```


```python
df1
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>employee</th>
      <th>group</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bob</td>
      <td>Accounting</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Jake</td>
      <td>Engineering</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Lisa</td>
      <td>Engineering</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sue</td>
      <td>HR</td>
    </tr>
  </tbody>
</table>
</div>




```python
df1a
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>group</th>
    </tr>
    <tr>
      <th>employee</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Bob</th>
      <td>Accounting</td>
    </tr>
    <tr>
      <th>Jake</th>
      <td>Engineering</td>
    </tr>
    <tr>
      <th>Lisa</th>
      <td>Engineering</td>
    </tr>
    <tr>
      <th>Sue</th>
      <td>HR</td>
    </tr>
  </tbody>
</table>
</div>




```python
df2
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>employee</th>
      <th>hire_date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Lisa</td>
      <td>2004</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Bob</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Jake</td>
      <td>2012</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sue</td>
      <td>2014</td>
    </tr>
  </tbody>
</table>
</div>



You can use the index as the key for merging by specifying the ``left_index`` and/or ``right_index`` flags in ``pd.merge()``:


```python
df2a
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>hire_date</th>
    </tr>
    <tr>
      <th>employee</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Lisa</th>
      <td>2004</td>
    </tr>
    <tr>
      <th>Bob</th>
      <td>2008</td>
    </tr>
    <tr>
      <th>Jake</th>
      <td>2012</td>
    </tr>
    <tr>
      <th>Sue</th>
      <td>2014</td>
    </tr>
  </tbody>
</table>
</div>




```python
pd.merge(df1a, df2a, left_index=True, right_index=True)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>group</th>
      <th>hire_date</th>
    </tr>
    <tr>
      <th>employee</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Lisa</th>
      <td>Engineering</td>
      <td>2004</td>
    </tr>
    <tr>
      <th>Bob</th>
      <td>Accounting</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>Jake</th>
      <td>Engineering</td>
      <td>2012</td>
    </tr>
    <tr>
      <th>Sue</th>
      <td>HR</td>
      <td>2014</td>
    </tr>
  </tbody>
</table>
</div>



For convenience, ``DataFrame``s implement the ``join()`` method, which performs a merge that defaults to joining on indices:


```python
df1a.join(df2a)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>group</th>
      <th>hire_date</th>
    </tr>
    <tr>
      <th>employee</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Bob</th>
      <td>Accounting</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>Jake</th>
      <td>Engineering</td>
      <td>2012</td>
    </tr>
    <tr>
      <th>Lisa</th>
      <td>Engineering</td>
      <td>2004</td>
    </tr>
    <tr>
      <th>Sue</th>
      <td>HR</td>
      <td>2014</td>
    </tr>
  </tbody>
</table>
</div>



__If you'd like to mix indices and columns, we can combine ``left_index`` with ``right_on`` or ``left_on`` with ``right_index`` to get the desired behavior:__


```python
df3
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bob</td>
      <td>70000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Jake</td>
      <td>80000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Lisa</td>
      <td>120000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sue</td>
      <td>90000</td>
    </tr>
  </tbody>
</table>
</div>




```python
pd.merge(df1a, df3, left_index=True, right_on='name')
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>group</th>
      <th>name</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Accounting</td>
      <td>Bob</td>
      <td>70000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Engineering</td>
      <td>Jake</td>
      <td>80000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Engineering</td>
      <td>Lisa</td>
      <td>120000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>HR</td>
      <td>Sue</td>
      <td>90000</td>
    </tr>
  </tbody>
</table>
</div>



## Specifying Set Arithmetic for Joins


```python
df6 = pd.DataFrame({'name': ['Peter', 'Paul', 'Mary'],
                    'food': ['fish', 'beans', 'bread']},
                   columns=['name', 'food'])
df7 = pd.DataFrame({'name': ['Mary', 'Joseph'],
                    'drink': ['wine', 'beer']},
                   columns=['name', 'drink'])
```


```python
df6
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>food</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Peter</td>
      <td>fish</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Paul</td>
      <td>beans</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Mary</td>
      <td>bread</td>
    </tr>
  </tbody>
</table>
</div>




```python
df7
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>drink</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Mary</td>
      <td>wine</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Joseph</td>
      <td>beer</td>
    </tr>
  </tbody>
</table>
</div>




```python
pd.merge(df6, df7)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>food</th>
      <th>drink</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Mary</td>
      <td>bread</td>
      <td>wine</td>
    </tr>
  </tbody>
</table>
</div>



when two datasets only have a single "name" entry in common:

By default, the result contains the *intersection* of the two sets of inputs; this is what is known as an *inner join*.

We can specify this explicitly using the ``how`` keyword, which defaults to ``"inner"``:


```python
pd.merge(df6, df7, how='inner')
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>food</th>
      <th>drink</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Mary</td>
      <td>bread</td>
      <td>wine</td>
    </tr>
  </tbody>
</table>
</div>



Other options for the ``how`` keyword are ``'outer'``, ``'left'``, and ``'right'``.
An *outer join* returns a join over the union of the input columns, and fills in all missing values with NAs:


```python
pd.merge(df6, df7, how='outer')
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>food</th>
      <th>drink</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Peter</td>
      <td>fish</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Paul</td>
      <td>beans</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Mary</td>
      <td>bread</td>
      <td>wine</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Joseph</td>
      <td>NaN</td>
      <td>beer</td>
    </tr>
  </tbody>
</table>
</div>



__The *left join* and *right join* return joins over the left entries and right entries, respectively.__
For example:


```python
pd.merge(df6, df7, how='left')
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>food</th>
      <th>drink</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Peter</td>
      <td>fish</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Paul</td>
      <td>beans</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Mary</td>
      <td>bread</td>
      <td>wine</td>
    </tr>
  </tbody>
</table>
</div>




```python
pd.merge(df6, df7, how='right')
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>food</th>
      <th>drink</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Mary</td>
      <td>bread</td>
      <td>wine</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Joseph</td>
      <td>NaN</td>
      <td>beer</td>
    </tr>
  </tbody>
</table>
</div>



## Overlapping Column Names: The ``suffixes`` Keyword


```python
df8 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],
                    'rank': [1, 2, 3, 4]})
df9 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],
                    'rank': [3, 1, 4, 2]})
pd.merge(df8, df9, on="name")
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>rank_x</th>
      <th>rank_y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bob</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Jake</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Lisa</td>
      <td>3</td>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sue</td>
      <td>4</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>



__Because the output would have two conflicting column names, the merge function automatically appends a suffix ``_x`` or ``_y`` to make the output columns unique.__

If these defaults are inappropriate, it is possible to specify a __custom suffix__ using the ``suffixes`` keyword:


```python
pd.merge(df8, df9, on="name", suffixes=["_left", "_right"])
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>rank_left</th>
      <th>rank_right</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Bob</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Jake</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Lisa</td>
      <td>3</td>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Sue</td>
      <td>4</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>



## Example: US States Data

[Download data here](http://github.com/jakevdp/data-USstates/):


```python
# !curl -O https://raw.githubusercontent.com/jakevdp/data-USstates/master/state-population.csv
# !curl -O https://raw.githubusercontent.com/jakevdp/data-USstates/master/state-areas.csv
# !curl -O https://raw.githubusercontent.com/jakevdp/data-USstates/master/state-abbrevs.csv
```

Let's take a look at the three datasets, using the Pandas ``read_csv()`` function:


```python
pop = pd.read_csv('/home/karen/Downloads/data/state-population.csv')
areas = pd.read_csv('/home/karen/Downloads/data/state-areas.csv')
abbrevs = pd.read_csv('/home/karen/Downloads/data/state-abbrevs.csv')
```


```python
pop.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state/region</th>
      <th>ages</th>
      <th>year</th>
      <th>population</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>AL</td>
      <td>under18</td>
      <td>2012</td>
      <td>1117489</td>
    </tr>
    <tr>
      <th>1</th>
      <td>AL</td>
      <td>total</td>
      <td>2012</td>
      <td>4817528</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AL</td>
      <td>under18</td>
      <td>2010</td>
      <td>1130966</td>
    </tr>
    <tr>
      <th>3</th>
      <td>AL</td>
      <td>total</td>
      <td>2010</td>
      <td>4785570</td>
    </tr>
    <tr>
      <th>4</th>
      <td>AL</td>
      <td>under18</td>
      <td>2011</td>
      <td>1125763</td>
    </tr>
  </tbody>
</table>
</div>




```python
areas.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>area (sq. mi)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Alabama</td>
      <td>52423</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Alaska</td>
      <td>656425</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Arizona</td>
      <td>114006</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Arkansas</td>
      <td>53182</td>
    </tr>
    <tr>
      <th>4</th>
      <td>California</td>
      <td>163707</td>
    </tr>
  </tbody>
</table>
</div>




```python
abbrevs.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state</th>
      <th>abbreviation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Alabama</td>
      <td>AL</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Alaska</td>
      <td>AK</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Arizona</td>
      <td>AZ</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Arkansas</td>
      <td>AR</td>
    </tr>
    <tr>
      <th>4</th>
      <td>California</td>
      <td>CA</td>
    </tr>
  </tbody>
</table>
</div>



Given this information, say we want to compute a relatively straightforward result: rank US states and territories by their 2010 population density.
We clearly have the data here to find this result, but we'll have to combine the datasets to find the result.

We'll start with a many-to-one merge that will give us the full state name within the population ``DataFrame``.
We want to merge based on the ``state/region``  column of ``pop``, and the ``abbreviation`` column of ``abbrevs``.
We'll use ``how='outer'`` to make sure no data is thrown away due to mismatched labels.


```python
merged = pd.merge(pop, abbrevs, how='outer',
                  left_on='state/region', right_on='abbreviation')
```


```python
merged.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state/region</th>
      <th>ages</th>
      <th>year</th>
      <th>population</th>
      <th>state</th>
      <th>abbreviation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>AL</td>
      <td>under18</td>
      <td>2012</td>
      <td>1117489</td>
      <td>Alabama</td>
      <td>AL</td>
    </tr>
    <tr>
      <th>1</th>
      <td>AL</td>
      <td>total</td>
      <td>2012</td>
      <td>4817528</td>
      <td>Alabama</td>
      <td>AL</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AL</td>
      <td>under18</td>
      <td>2010</td>
      <td>1130966</td>
      <td>Alabama</td>
      <td>AL</td>
    </tr>
    <tr>
      <th>3</th>
      <td>AL</td>
      <td>total</td>
      <td>2010</td>
      <td>4785570</td>
      <td>Alabama</td>
      <td>AL</td>
    </tr>
    <tr>
      <th>4</th>
      <td>AL</td>
      <td>under18</td>
      <td>2011</td>
      <td>1125763</td>
      <td>Alabama</td>
      <td>AL</td>
    </tr>
  </tbody>
</table>
</div>




```python
merged.tail()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state/region</th>
      <th>ages</th>
      <th>year</th>
      <th>population</th>
      <th>state</th>
      <th>abbreviation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2539</th>
      <td>USA</td>
      <td>total</td>
      <td>2010</td>
      <td>309326295</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2540</th>
      <td>USA</td>
      <td>under18</td>
      <td>2011</td>
      <td>73902222</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2541</th>
      <td>USA</td>
      <td>total</td>
      <td>2011</td>
      <td>311582564</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2542</th>
      <td>USA</td>
      <td>under18</td>
      <td>2012</td>
      <td>73708179</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2543</th>
      <td>USA</td>
      <td>total</td>
      <td>2012</td>
      <td>313873685</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




```python
merged = merged.drop('abbreviation', 1) # drop duplicate info
merged.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state/region</th>
      <th>ages</th>
      <th>year</th>
      <th>population</th>
      <th>state</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>AL</td>
      <td>under18</td>
      <td>2012</td>
      <td>1117489</td>
      <td>Alabama</td>
    </tr>
    <tr>
      <th>1</th>
      <td>AL</td>
      <td>total</td>
      <td>2012</td>
      <td>4817528</td>
      <td>Alabama</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AL</td>
      <td>under18</td>
      <td>2010</td>
      <td>1130966</td>
      <td>Alabama</td>
    </tr>
    <tr>
      <th>3</th>
      <td>AL</td>
      <td>total</td>
      <td>2010</td>
      <td>4785570</td>
      <td>Alabama</td>
    </tr>
    <tr>
      <th>4</th>
      <td>AL</td>
      <td>under18</td>
      <td>2011</td>
      <td>1125763</td>
      <td>Alabama</td>
    </tr>
  </tbody>
</table>
</div>



Let's double-check whether there were any mismatches here, which we can do by looking for rows with nulls:


```python
merged.isnull().any()
```




    state/region    False
    ages            False
    year            False
    population       True
    state            True
    dtype: bool



Some of the ``population`` info is null:


```python
merged[merged['population'].isnull()].head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state/region</th>
      <th>ages</th>
      <th>year</th>
      <th>population</th>
      <th>state</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2448</th>
      <td>PR</td>
      <td>under18</td>
      <td>1990</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2449</th>
      <td>PR</td>
      <td>total</td>
      <td>1990</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2450</th>
      <td>PR</td>
      <td>total</td>
      <td>1991</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2451</th>
      <td>PR</td>
      <td>under18</td>
      <td>1991</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2452</th>
      <td>PR</td>
      <td>total</td>
      <td>1993</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>



It appears that all the null population values are from Puerto Rico prior to the year 2000; this is likely due to this data not being available from the original source.

More importantly, we see also that some of the new ``state`` entries are also null, which means that there was no corresponding entry in the ``abbrevs`` key!
Let's figure out which regions lack this match:


```python
merged.loc[merged['state'].isnull(), 'state/region'].head()
```




    2448    PR
    2449    PR
    2450    PR
    2451    PR
    2452    PR
    Name: state/region, dtype: object




```python
merged.loc[merged['state'].isnull(), 'state/region'].tail()
```




    2539    USA
    2540    USA
    2541    USA
    2542    USA
    2543    USA
    Name: state/region, dtype: object




```python
merged.loc[merged['state'].isnull(), 'state/region'].unique()
```




   array(['PR', 'USA'], dtype=object)



We can quickly infer the issue: our population data includes entries for Puerto Rico (PR) and the United States as a whole (USA), while these entries do not appear in the state abbreviation key.
We can fix these quickly by filling in appropriate entries:


```python
merged.loc[merged['state/region'] == 'PR', 'state'].head()
```




    2448    NaN
    2449    NaN
    2450    NaN
    2451    NaN
    2452    NaN
    Name: state, dtype: object




```python
merged.loc[merged['state/region'] == 'PR', 'state'] = 'Puerto Rico'
merged.loc[merged['state/region'] == 'USA', 'state'] = 'United States'
merged.isnull().any()
```




    state/region    False
    ages            False
    year            False
    population       True
    state           False
    dtype: bool




```python
merged.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state/region</th>
      <th>ages</th>
      <th>year</th>
      <th>population</th>
      <th>state</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>AL</td>
      <td>under18</td>
      <td>2012</td>
      <td>1117489</td>
      <td>Alabama</td>
    </tr>
    <tr>
      <th>1</th>
      <td>AL</td>
      <td>total</td>
      <td>2012</td>
      <td>4817528</td>
      <td>Alabama</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AL</td>
      <td>under18</td>
      <td>2010</td>
      <td>1130966</td>
      <td>Alabama</td>
    </tr>
    <tr>
      <th>3</th>
      <td>AL</td>
      <td>total</td>
      <td>2010</td>
      <td>4785570</td>
      <td>Alabama</td>
    </tr>
    <tr>
      <th>4</th>
      <td>AL</td>
      <td>under18</td>
      <td>2011</td>
      <td>1125763</td>
      <td>Alabama</td>
    </tr>
  </tbody>
</table>
</div>




```python
final = pd.merge(merged, areas, on='state', how='left')
final.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state/region</th>
      <th>ages</th>
      <th>year</th>
      <th>population</th>
      <th>state</th>
      <th>area (sq. mi)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>AL</td>
      <td>under18</td>
      <td>2012</td>
      <td>1117489</td>
      <td>Alabama</td>
      <td>52423</td>
    </tr>
    <tr>
      <th>1</th>
      <td>AL</td>
      <td>total</td>
      <td>2012</td>
      <td>4817528</td>
      <td>Alabama</td>
      <td>52423</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AL</td>
      <td>under18</td>
      <td>2010</td>
      <td>1130966</td>
      <td>Alabama</td>
      <td>52423</td>
    </tr>
    <tr>
      <th>3</th>
      <td>AL</td>
      <td>total</td>
      <td>2010</td>
      <td>4785570</td>
      <td>Alabama</td>
      <td>52423</td>
    </tr>
    <tr>
      <th>4</th>
      <td>AL</td>
      <td>under18</td>
      <td>2011</td>
      <td>1125763</td>
      <td>Alabama</td>
      <td>52423</td>
    </tr>
  </tbody>
</table>
</div>



Again, let's check for nulls to see if there were any mismatches:


```python
final.isnull().any()
```




    state/region     False
    ages             False
    year             False
    population        True
    state            False
    area (sq. mi)     True
    dtype: bool



There are nulls in the ``area`` column; 

> which regions were ignored?


```python
final['state'][final['area (sq. mi)'].isnull()].unique()
```




   array(['United States'], dtype=object)



We see that our ``areas`` ``DataFrame`` does not contain the area of the United States as a whole.



```python
final.dropna(inplace=True)
final.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state/region</th>
      <th>ages</th>
      <th>year</th>
      <th>population</th>
      <th>state</th>
      <th>area (sq. mi)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>AL</td>
      <td>under18</td>
      <td>2012</td>
      <td>1117489</td>
      <td>Alabama</td>
      <td>52423</td>
    </tr>
    <tr>
      <th>1</th>
      <td>AL</td>
      <td>total</td>
      <td>2012</td>
      <td>4817528</td>
      <td>Alabama</td>
      <td>52423</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AL</td>
      <td>under18</td>
      <td>2010</td>
      <td>1130966</td>
      <td>Alabama</td>
      <td>52423</td>
    </tr>
    <tr>
      <th>3</th>
      <td>AL</td>
      <td>total</td>
      <td>2010</td>
      <td>4785570</td>
      <td>Alabama</td>
      <td>52423</td>
    </tr>
    <tr>
      <th>4</th>
      <td>AL</td>
      <td>under18</td>
      <td>2011</td>
      <td>1125763</td>
      <td>Alabama</td>
      <td>52423</td>
    </tr>
  </tbody>
</table>
</div>



Now we have all the data we need. To answer the question of interest, let's first select the portion of the data corresponding with the year 2000, and the total population.
We'll use the ``query()`` function to do this quickly (this requires the ``numexpr`` package to be installed; see [High-Performance Pandas: ``eval()`` and ``query()``](03.12-Performance-Eval-and-Query.ipynb)):


```python
final=final.rename(columns={'area (sq. mi)':'area'})
final.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state/region</th>
      <th>ages</th>
      <th>year</th>
      <th>population</th>
      <th>state</th>
      <th>area</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>AL</td>
      <td>under18</td>
      <td>2012</td>
      <td>1117489</td>
      <td>Alabama</td>
      <td>52423</td>
    </tr>
    <tr>
      <th>1</th>
      <td>AL</td>
      <td>total</td>
      <td>2012</td>
      <td>4817528</td>
      <td>Alabama</td>
      <td>52423</td>
    </tr>
    <tr>
      <th>2</th>
      <td>AL</td>
      <td>under18</td>
      <td>2010</td>
      <td>1130966</td>
      <td>Alabama</td>
      <td>52423</td>
    </tr>
    <tr>
      <th>3</th>
      <td>AL</td>
      <td>total</td>
      <td>2010</td>
      <td>4785570</td>
      <td>Alabama</td>
      <td>52423</td>
    </tr>
    <tr>
      <th>4</th>
      <td>AL</td>
      <td>under18</td>
      <td>2011</td>
      <td>1125763</td>
      <td>Alabama</td>
      <td>52423</td>
    </tr>
  </tbody>
</table>
</div>




```python
# must install numexpr first
data2010 = final.query("year == 2010 & ages == 'total'")
data2010.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state/region</th>
      <th>ages</th>
      <th>year</th>
      <th>population</th>
      <th>state</th>
      <th>area</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3</th>
      <td>AL</td>
      <td>total</td>
      <td>2010</td>
      <td>4785570</td>
      <td>Alabama</td>
      <td>52423</td>
    </tr>
    <tr>
      <th>91</th>
      <td>AK</td>
      <td>total</td>
      <td>2010</td>
      <td>713868</td>
      <td>Alaska</td>
      <td>656425</td>
    </tr>
    <tr>
      <th>101</th>
      <td>AZ</td>
      <td>total</td>
      <td>2010</td>
      <td>6408790</td>
      <td>Arizona</td>
      <td>114006</td>
    </tr>
    <tr>
      <th>189</th>
      <td>AR</td>
      <td>total</td>
      <td>2010</td>
      <td>2922280</td>
      <td>Arkansas</td>
      <td>53182</td>
    </tr>
    <tr>
      <th>197</th>
      <td>CA</td>
      <td>total</td>
      <td>2010</td>
      <td>37333601</td>
      <td>California</td>
      <td>163707</td>
    </tr>
  </tbody>
</table>
</div>



Now let's compute the population density and display it in order.
We'll start by re-indexing our data on the state, and then compute the result:


```python
data2010.set_index('state', inplace=True)
data2010
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state/region</th>
      <th>ages</th>
      <th>year</th>
      <th>population</th>
      <th>area</th>
    </tr>
    <tr>
      <th>state</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Alabama</th>
      <td>AL</td>
      <td>total</td>
      <td>2010</td>
      <td>4785570</td>
      <td>52423</td>
    </tr>
    <tr>
      <th>Alaska</th>
      <td>AK</td>
      <td>total</td>
      <td>2010</td>
      <td>713868</td>
      <td>656425</td>
    </tr>
    <tr>
      <th>Arizona</th>
      <td>AZ</td>
      <td>total</td>
      <td>2010</td>
      <td>6408790</td>
      <td>114006</td>
    </tr>
    <tr>
      <th>Arkansas</th>
      <td>AR</td>
      <td>total</td>
      <td>2010</td>
      <td>2922280</td>
      <td>53182</td>
    </tr>
    <tr>
      <th>California</th>
      <td>CA</td>
      <td>total</td>
      <td>2010</td>
      <td>37333601</td>
      <td>163707</td>
    </tr>
    <tr>
      <th>Colorado</th>
      <td>CO</td>
      <td>total</td>
      <td>2010</td>
      <td>5048196</td>
      <td>104100</td>
    </tr>
    <tr>
      <th>Connecticut</th>
      <td>CT</td>
      <td>total</td>
      <td>2010</td>
      <td>3579210</td>
      <td>5544</td>
    </tr>
    <tr>
      <th>Delaware</th>
      <td>DE</td>
      <td>total</td>
      <td>2010</td>
      <td>899711</td>
      <td>1954</td>
    </tr>
    <tr>
      <th>District of Columbia</th>
      <td>DC</td>
      <td>total</td>
      <td>2010</td>
      <td>605125</td>
      <td>68</td>
    </tr>
    <tr>
      <th>Florida</th>
      <td>FL</td>
      <td>total</td>
      <td>2010</td>
      <td>18846054</td>
      <td>65758</td>
    </tr>
    <tr>
      <th>Georgia</th>
      <td>GA</td>
      <td>total</td>
      <td>2010</td>
      <td>9713248</td>
      <td>59441</td>
    </tr>
    <tr>
      <th>Hawaii</th>
      <td>HI</td>
      <td>total</td>
      <td>2010</td>
      <td>1363731</td>
      <td>10932</td>
    </tr>
    <tr>
      <th>Idaho</th>
      <td>ID</td>
      <td>total</td>
      <td>2010</td>
      <td>1570718</td>
      <td>83574</td>
    </tr>
    <tr>
      <th>Illinois</th>
      <td>IL</td>
      <td>total</td>
      <td>2010</td>
      <td>12839695</td>
      <td>57918</td>
    </tr>
    <tr>
      <th>Indiana</th>
      <td>IN</td>
      <td>total</td>
      <td>2010</td>
      <td>6489965</td>
      <td>36420</td>
    </tr>
    <tr>
      <th>Iowa</th>
      <td>IA</td>
      <td>total</td>
      <td>2010</td>
      <td>3050314</td>
      <td>56276</td>
    </tr>
    <tr>
      <th>Kansas</th>
      <td>KS</td>
      <td>total</td>
      <td>2010</td>
      <td>2858910</td>
      <td>82282</td>
    </tr>
    <tr>
      <th>Kentucky</th>
      <td>KY</td>
      <td>total</td>
      <td>2010</td>
      <td>4347698</td>
      <td>40411</td>
    </tr>
    <tr>
      <th>Louisiana</th>
      <td>LA</td>
      <td>total</td>
      <td>2010</td>
      <td>4545392</td>
      <td>51843</td>
    </tr>
    <tr>
      <th>Maine</th>
      <td>ME</td>
      <td>total</td>
      <td>2010</td>
      <td>1327366</td>
      <td>35387</td>
    </tr>
    <tr>
      <th>Maryland</th>
      <td>MD</td>
      <td>total</td>
      <td>2010</td>
      <td>5787193</td>
      <td>12407</td>
    </tr>
    <tr>
      <th>Massachusetts</th>
      <td>MA</td>
      <td>total</td>
      <td>2010</td>
      <td>6563263</td>
      <td>10555</td>
    </tr>
    <tr>
      <th>Michigan</th>
      <td>MI</td>
      <td>total</td>
      <td>2010</td>
      <td>9876149</td>
      <td>96810</td>
    </tr>
    <tr>
      <th>Minnesota</th>
      <td>MN</td>
      <td>total</td>
      <td>2010</td>
      <td>5310337</td>
      <td>86943</td>
    </tr>
    <tr>
      <th>Mississippi</th>
      <td>MS</td>
      <td>total</td>
      <td>2010</td>
      <td>2970047</td>
      <td>48434</td>
    </tr>
    <tr>
      <th>Missouri</th>
      <td>MO</td>
      <td>total</td>
      <td>2010</td>
      <td>5996063</td>
      <td>69709</td>
    </tr>
    <tr>
      <th>Montana</th>
      <td>MT</td>
      <td>total</td>
      <td>2010</td>
      <td>990527</td>
      <td>147046</td>
    </tr>
    <tr>
      <th>Nebraska</th>
      <td>NE</td>
      <td>total</td>
      <td>2010</td>
      <td>1829838</td>
      <td>77358</td>
    </tr>
    <tr>
      <th>Nevada</th>
      <td>NV</td>
      <td>total</td>
      <td>2010</td>
      <td>2703230</td>
      <td>110567</td>
    </tr>
    <tr>
      <th>New Hampshire</th>
      <td>NH</td>
      <td>total</td>
      <td>2010</td>
      <td>1316614</td>
      <td>9351</td>
    </tr>
    <tr>
      <th>New Jersey</th>
      <td>NJ</td>
      <td>total</td>
      <td>2010</td>
      <td>8802707</td>
      <td>8722</td>
    </tr>
    <tr>
      <th>New Mexico</th>
      <td>NM</td>
      <td>total</td>
      <td>2010</td>
      <td>2064982</td>
      <td>121593</td>
    </tr>
    <tr>
      <th>New York</th>
      <td>NY</td>
      <td>total</td>
      <td>2010</td>
      <td>19398228</td>
      <td>54475</td>
    </tr>
    <tr>
      <th>North Carolina</th>
      <td>NC</td>
      <td>total</td>
      <td>2010</td>
      <td>9559533</td>
      <td>53821</td>
    </tr>
    <tr>
      <th>North Dakota</th>
      <td>ND</td>
      <td>total</td>
      <td>2010</td>
      <td>674344</td>
      <td>70704</td>
    </tr>
    <tr>
      <th>Ohio</th>
      <td>OH</td>
      <td>total</td>
      <td>2010</td>
      <td>11545435</td>
      <td>44828</td>
    </tr>
    <tr>
      <th>Oklahoma</th>
      <td>OK</td>
      <td>total</td>
      <td>2010</td>
      <td>3759263</td>
      <td>69903</td>
    </tr>
    <tr>
      <th>Oregon</th>
      <td>OR</td>
      <td>total</td>
      <td>2010</td>
      <td>3837208</td>
      <td>98386</td>
    </tr>
    <tr>
      <th>Pennsylvania</th>
      <td>PA</td>
      <td>total</td>
      <td>2010</td>
      <td>12710472</td>
      <td>46058</td>
    </tr>
    <tr>
      <th>Rhode Island</th>
      <td>RI</td>
      <td>total</td>
      <td>2010</td>
      <td>1052669</td>
      <td>1545</td>
    </tr>
    <tr>
      <th>South Carolina</th>
      <td>SC</td>
      <td>total</td>
      <td>2010</td>
      <td>4636361</td>
      <td>32007</td>
    </tr>
    <tr>
      <th>South Dakota</th>
      <td>SD</td>
      <td>total</td>
      <td>2010</td>
      <td>816211</td>
      <td>77121</td>
    </tr>
    <tr>
      <th>Tennessee</th>
      <td>TN</td>
      <td>total</td>
      <td>2010</td>
      <td>6356683</td>
      <td>42146</td>
    </tr>
    <tr>
      <th>Texas</th>
      <td>TX</td>
      <td>total</td>
      <td>2010</td>
      <td>25245178</td>
      <td>268601</td>
    </tr>
    <tr>
      <th>Utah</th>
      <td>UT</td>
      <td>total</td>
      <td>2010</td>
      <td>2774424</td>
      <td>84904</td>
    </tr>
    <tr>
      <th>Vermont</th>
      <td>VT</td>
      <td>total</td>
      <td>2010</td>
      <td>625793</td>
      <td>9615</td>
    </tr>
    <tr>
      <th>Virginia</th>
      <td>VA</td>
      <td>total</td>
      <td>2010</td>
      <td>8024417</td>
      <td>42769</td>
    </tr>
    <tr>
      <th>Washington</th>
      <td>WA</td>
      <td>total</td>
      <td>2010</td>
      <td>6742256</td>
      <td>71303</td>
    </tr>
    <tr>
      <th>West Virginia</th>
      <td>WV</td>
      <td>total</td>
      <td>2010</td>
      <td>1854146</td>
      <td>24231</td>
    </tr>
    <tr>
      <th>Wisconsin</th>
      <td>WI</td>
      <td>total</td>
      <td>2010</td>
      <td>5689060</td>
      <td>65503</td>
    </tr>
    <tr>
      <th>Wyoming</th>
      <td>WY</td>
      <td>total</td>
      <td>2010</td>
      <td>564222</td>
      <td>97818</td>
    </tr>
    <tr>
      <th>Puerto Rico</th>
      <td>PR</td>
      <td>total</td>
      <td>2010</td>
      <td>3721208</td>
      <td>3515</td>
    </tr>
  </tbody>
</table>
</div>




```python
data2010.sort_values(by=['area', 'population'],ascending=False, inplace=True)
data2010.head()
```

    /usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
      """Entry point for launching an IPython kernel.





<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state/region</th>
      <th>ages</th>
      <th>year</th>
      <th>population</th>
      <th>area</th>
    </tr>
    <tr>
      <th>state</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Alaska</th>
      <td>AK</td>
      <td>total</td>
      <td>2010</td>
      <td>713868</td>
      <td>656425</td>
    </tr>
    <tr>
      <th>Texas</th>
      <td>TX</td>
      <td>total</td>
      <td>2010</td>
      <td>25245178</td>
      <td>268601</td>
    </tr>
    <tr>
      <th>California</th>
      <td>CA</td>
      <td>total</td>
      <td>2010</td>
      <td>37333601</td>
      <td>163707</td>
    </tr>
    <tr>
      <th>Montana</th>
      <td>MT</td>
      <td>total</td>
      <td>2010</td>
      <td>990527</td>
      <td>147046</td>
    </tr>
    <tr>
      <th>New Mexico</th>
      <td>NM</td>
      <td>total</td>
      <td>2010</td>
      <td>2064982</td>
      <td>121593</td>
    </tr>
  </tbody>
</table>
</div>




```python
data2010.sort_values(by=['population', 'area'],ascending=False, inplace=True)
data2010.head()
```

    /usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
      """Entry point for launching an IPython kernel.





<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state/region</th>
      <th>ages</th>
      <th>year</th>
      <th>population</th>
      <th>area</th>
    </tr>
    <tr>
      <th>state</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>California</th>
      <td>CA</td>
      <td>total</td>
      <td>2010</td>
      <td>37333601</td>
      <td>163707</td>
    </tr>
    <tr>
      <th>Texas</th>
      <td>TX</td>
      <td>total</td>
      <td>2010</td>
      <td>25245178</td>
      <td>268601</td>
    </tr>
    <tr>
      <th>New York</th>
      <td>NY</td>
      <td>total</td>
      <td>2010</td>
      <td>19398228</td>
      <td>54475</td>
    </tr>
    <tr>
      <th>Florida</th>
      <td>FL</td>
      <td>total</td>
      <td>2010</td>
      <td>18846054</td>
      <td>65758</td>
    </tr>
    <tr>
      <th>Illinois</th>
      <td>IL</td>
      <td>total</td>
      <td>2010</td>
      <td>12839695</td>
      <td>57918</td>
    </tr>
  </tbody>
</table>
</div>




```python
data2010.head(10) # the top 10 state with most population
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>state/region</th>
      <th>ages</th>
      <th>year</th>
      <th>population</th>
      <th>area</th>
    </tr>
    <tr>
      <th>state</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>California</th>
      <td>CA</td>
      <td>total</td>
      <td>2010</td>
      <td>37333601</td>
      <td>163707</td>
    </tr>
    <tr>
      <th>Texas</th>
      <td>TX</td>
      <td>total</td>
      <td>2010</td>
      <td>25245178</td>
      <td>268601</td>
    </tr>
    <tr>
      <th>New York</th>
      <td>NY</td>
      <td>total</td>
      <td>2010</td>
      <td>19398228</td>
      <td>54475</td>
    </tr>
    <tr>
      <th>Florida</th>
      <td>FL</td>
      <td>total</td>
      <td>2010</td>
      <td>18846054</td>
      <td>65758</td>
    </tr>
    <tr>
      <th>Illinois</th>
      <td>IL</td>
      <td>total</td>
      <td>2010</td>
      <td>12839695</td>
      <td>57918</td>
    </tr>
    <tr>
      <th>Pennsylvania</th>
      <td>PA</td>
      <td>total</td>
      <td>2010</td>
      <td>12710472</td>
      <td>46058</td>
    </tr>
    <tr>
      <th>Ohio</th>
      <td>OH</td>
      <td>total</td>
      <td>2010</td>
      <td>11545435</td>
      <td>44828</td>
    </tr>
    <tr>
      <th>Michigan</th>
      <td>MI</td>
      <td>total</td>
      <td>2010</td>
      <td>9876149</td>
      <td>96810</td>
    </tr>
    <tr>
      <th>Georgia</th>
      <td>GA</td>
      <td>total</td>
      <td>2010</td>
      <td>9713248</td>
      <td>59441</td>
    </tr>
    <tr>
      <th>North Carolina</th>
      <td>NC</td>
      <td>total</td>
      <td>2010</td>
      <td>9559533</td>
      <td>53821</td>
    </tr>
  </tbody>
</table>
</div>

<style>

table {
    border-collapse: collapse;
}

table, th, td {
    border: 1px solid black;
}

table {
    border: 1px solid black;
}

tr:hover {background-color: #f5f5f5;}

tr:nth-child(even) {background-color: #f2f2f2;}

th, td {
    padding: 10px;
    text-align: center;
}
</style>