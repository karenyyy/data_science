{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "\n",
    "- Each neuron receives some inputs, performs a dot product and optionally follows it with a non-linearity function. \n",
    "- The whole network represents **a single differentiable score function.**\n",
    "- This function takes in as input raw image pixels on one end and computes class scores at the other. \n",
    "- The output scores are fed into a loss function to compute the multinomial class probabilities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main components\n",
    "\n",
    "- inputs matrix - image 4D tensor\n",
    "- output class scores\n",
    "- convolutional layers\n",
    "- fully-connected layers\n",
    "- activation functions\n",
    "- max-pooling layers\n",
    "- dropout layers\n",
    "- softmax layer for multinomial class probabilities\n",
    "- loss function\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/convnet.jpeg\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected (Dense) Layer (weighted sum)\n",
    "\n",
    "<div style=\"float:right;margin-right:5px;\">\n",
    "    <img src=\"images/SingleNeuron.png\" width=\"300\" />\n",
    "    <p style=\"text-align:center;\">*Single feedforward neuron*</p>\n",
    "</div>\n",
    "<br>\n",
    "**Feedforward computation**\n",
    "\n",
    "$\\textstyle h_{W,b}(x) = f(W^Tx) = f(\\sum_{i=1}^3 W_{i}x_i +b)$ <br>\n",
    "\n",
    "$f =$ activation function <br>\n",
    "$W =$ weight vector/matrix <br>\n",
    "$b =$ bias scalar/vector <br>\n",
    "\n",
    "\n",
    "**Fully connected layers are not spatially located since there is no weight sharing. Therefore the input to a fully connect layer must be reshaped to a vector.**\n",
    "\n",
    "\n",
    "### Fully Connected Neural Network\n",
    "<br>\n",
    "<img src=\"images/NN1.gif\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer\n",
    "\n",
    "#### CNN components\n",
    "   - learnable filters (or kernels)\n",
    "        - have a small receptive field\n",
    "        - extend through the full depth of the input volume\n",
    "        - during the forward pass, each filter is convolved across the width and height of the input volume, computing the dot product between the entries of the filter and the input and producing a 2-dimensional activation map of that filter. \n",
    "        - as a result, the network learns filters that activate when it detects some specific type of feature at some spatial position in the input. \n",
    "        - stacking the activation maps for all filters along the depth dimension forms the full output volume of the convolution layer.\n",
    "\n",
    "\n",
    "<br>\n",
    "<div style=\"float:left;margin-right:5px;\">\n",
    "    <img src=\"images/Conv3.jpeg\" width=\"300\" />\n",
    "    <p style=\"text-align:center;\">*2D Convolution on color image*</p>\n",
    "</div>\n",
    "<div style=\"float:center;margin-right:5px;\">\n",
    "    <img src=\"images/neuron_model.jpeg\" width=\"350\" />\n",
    "    <p style=\"text-align:center;\">*A Neural Network \"neuron\"*</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "#### Benefits of CNN:\n",
    "\n",
    "1. **Location Invariance** -  because of the sliding filters, **the exact location of important features is not important**, which allows the model to generalize better to unseen images (pooling also provides invariance)\n",
    "\n",
    "2. **Local connectivity** - Convolutional networks exploit spatially local correlation by **enforcing a local connectivity pattern (receptive field) between neurons of adjacent layers.** This is in contrast to fully connected layers that do not take into account the spatial structure of the input.\n",
    "\n",
    "3. **Compositionality** -  CNN layers are generally stacked on top of eachother. Allowing the model to construct incrementally higher-level representation of the image, making the classification task easier at the last layer.\n",
    "\n",
    "\n",
    "<img src=\"images/Convolution.gif\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Layer\n",
    "\n",
    "- (preferable, faster, generalization accuracy) **ReLu** (Rectified Linear Unit) $f(x)=\\max(0,x)$\n",
    "\n",
    "- tanh $f(x)=\\tanh(x)$ \n",
    "\n",
    "- sigmoid $f(x)=(1+e^{-x})^{-1}$\n",
    "\n",
    "\n",
    "<img src=\"images/activations.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling Layer (downsampling)\n",
    "\n",
    "- Max-pooling \n",
    "- Average pooling\n",
    "- L2-norm pooling.\n",
    "\n",
    "### Intuitive reasoning behind this layer\n",
    "\n",
    "- Once we know that a specific feature is in the original input volume (there will be a high activation value), **its exact location is not as important as its relative location to the other features.** \n",
    "- This layer drastically reduces the spatial dimension (the length and the width change but not the depth) of the input tensor.\n",
    "\n",
    "    - 1. Reduce the amount of parameters and computation in the network\n",
    "    - 2. Control overfitting (high train accuracy but low test accuracy)\n",
    "\n",
    "\n",
    "<br>\n",
    "<div style=\"float:left;margin-right:5px;\">\n",
    "    <img src=\"images/pool.jpeg\" width=\"300\" />\n",
    "    <p style=\"text-align:center;\">*Spatial downsampling with filter size 2, stride 2*</p>\n",
    "</div>\n",
    "<div style=\"float:center;margin-right:5px;\">\n",
    "    <img src=\"images/maxpool.jpeg\" width=\"400\" />\n",
    "    <p style=\"text-align:center;\">*Maxpooling operation*</p>\n",
    "</div>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout Layer\n",
    "\n",
    "<img src=\"images/dropout1.png\" width=\"600\">\n",
    "\n",
    "Overly complex models can lead to the problem of overfitting. \n",
    "\n",
    "The solution is to apply regularization. \n",
    "\n",
    "   - Add the L2-norm of the model's weights to the cost function\n",
    "        - penalize peaky weight vectors \n",
    "        - prefer diffuse weight vectors\n",
    "        - force the network to use all of its inputs a little rather that some of its inputs a lot.\n",
    "\n",
    "\n",
    "\n",
    "   - Dropout (complements the other regularization methods)\n",
    "        - this layer “drops out” a random set of activations in that layer **by setting them to zero in the forward pass*.  \n",
    "        - it forces the network to provide the right classification or output for a specific example even if some of the activations are dropped out. \n",
    "        - **during testing there is no dropout applied**\n",
    "        \n",
    "       "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
