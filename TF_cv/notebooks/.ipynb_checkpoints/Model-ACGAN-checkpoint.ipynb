{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tf.contrib.keras.models\n",
    "layers = tf.contrib.keras.layers\n",
    "utils = tf.contrib.keras.utils\n",
    "losses = tf.contrib.keras.losses\n",
    "optimizers = tf.contrib.keras.optimizers \n",
    "metrics = tf.contrib.keras.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_image = tf.contrib.keras.preprocessing.image\n",
    "datasets = tf.contrib.keras.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator\n",
    "<img src=\"../images/acgan-3.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " def up_sampling_block(x, filter_number):\n",
    "        # upsample block\n",
    "        # factor = stride = 2\n",
    "        x = layers.UpSampling2D(size=(2,2))(x)\n",
    "        x = layers.Conv2D(filter_number, (5,5), padding='same', activation='relu')(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes: \n",
    "\n",
    "- #### `Glorot normal initializer`, also called Xavier normal initializer.\n",
    "\n",
    "    - It draws samples from a `truncated normal distribution` centered on 0 with $$stddev = \\sqrt{\\frac{2}{fan_{in} + fan_{out}}}$$ \n",
    "\n",
    "        - fan_in is the `number of input units in the weight tensor` \n",
    "        - fan_out is the `number of output units in the weight tensor`\n",
    "\n",
    "\n",
    "- #### `Hadamard product` (also known as the Schur product or the entrywise product)\n",
    "\n",
    "Hadamard product is a binary operation that `takes two matrices of the same dimensions, and produces another matrix with the same dimension`, where each element i,j is the product of elements i,j of the original two matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(latent_size, classes=10):\n",
    "    \n",
    "    #######################\n",
    "    ####### Input 1########\n",
    "    \n",
    "    # image class label\n",
    "    image_class = layers.Input(shape=(1,), dtype='int32')\n",
    "    \n",
    "    # class embeddings\n",
    "    # reconstruct: 10 => 100\n",
    "    emb = layers.Embedding(classes, latent_size,\n",
    "                           embeddings_initializer='glorot_normal')(image_class)\n",
    "    \n",
    "    # 10 classes in MNIST\n",
    "    fc_embedding = layers.Flatten()(emb)\n",
    "    \n",
    "    #######################\n",
    "    ####### Input 2########\n",
    "    \n",
    "    # latent noise vector\n",
    "    latent_input = layers.Input(shape=(latent_size,))\n",
    "    \n",
    "    # hadamard product between latent embedding and a class conditional embedding\n",
    "    h = layers.multiply([latent_input, fc_embedding])\n",
    "    \n",
    "    #########################################################\n",
    "    ####### generator part 1: dense layer and reshape########\n",
    "    \n",
    "    x = layers.Dense(1024, activation='relu')(h)\n",
    "    x = layers.Dense(128 * 7 * 7, activation='relu')(x)\n",
    "    x = layers.Reshape((7, 7, 128))(x)\n",
    "    \n",
    "    #############################################################\n",
    "    ####### generator part 2: upsampling and reconstruct ########\n",
    "    \n",
    "    # upsample to (14, 14, 128)\n",
    "    x = up_sampling_block(x, 128)\n",
    "    \n",
    "    # upsample to (28, 28, 256)\n",
    "    x = up_sampling_block(x, 256)\n",
    "    \n",
    "    ############################################################\n",
    "    ####### generator part 3: conv layer and reduce dim ########\n",
    "    \n",
    "    # reduce channel into binary image (28, 28, 1)\n",
    "    generated_img = layers.Conv2D(1, (2,2), padding='same', activation='tanh')(x)\n",
    "    \n",
    "    return models.Model(inputs=[latent_input, image_class], # here: since ACGAN is GAN with conditional label attached\n",
    "                        outputs=generated_img,\n",
    "                        name='generator') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, 1, 100)        1000        input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "input_5 (InputLayer)             (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 100)           0           embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)            (None, 100)           0           input_5[0][0]                    \n",
      "                                                                   flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 1024)          103424      multiply_3[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 6272)          6428800     dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)              (None, 7, 7, 128)     0           dense_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)   (None, 14, 14, 128)   0           reshape_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 14, 14, 128)   409728      up_sampling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)   (None, 28, 28, 128)   0           conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 28, 28, 256)   819456      up_sampling2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 28, 28, 1)     1025        conv2d_8[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 7,763,433\n",
      "Trainable params: 7,763,433\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g = generator(latent_size = 100, classes=10)\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator\n",
    "<img src=\"../images/acgan-3.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, filter_number, stride):\n",
    "    x = layers.Conv2D(filter_number, (3,3), padding='same', strides=stride)(x)\n",
    "    x = layers.LeakyReLU()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(input_shape=(28, 28, 1)):\n",
    "\n",
    "    input_img = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # discriminator network\n",
    "    x = conv_block(input_img, 32, (2,2))\n",
    "    x = conv_block(input_img, 64, (1,1))\n",
    "    x = conv_block(input_img, 128, (2,2))\n",
    "    x = conv_block(input_img, 256, (1,1))\n",
    "    \n",
    "    features = layers.Flatten()(x)\n",
    "    \n",
    "    # binary classifier, image fake or real\n",
    "    fake = layers.Dense(1, activation='sigmoid', name='generation')(features)\n",
    "    \n",
    "    # multi-class classifier, image digit class\n",
    "    aux = layers.Dense(10, activation='softmax', name='auxiliary')(features)\n",
    "    \n",
    "    return models.Model(inputs=input_img, outputs=[fake, aux], name='discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_10 (InputLayer)            (None, 28, 28, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)               (None, 28, 28, 256)   2560        input_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)       (None, 28, 28, 256)   0           conv2d_24[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)             (None, 28, 28, 256)   0           leaky_re_lu_12[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)              (None, 200704)        0           dropout_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "generation (Dense)               (None, 1)             200705      flatten_7[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "auxiliary (Dense)                (None, 10)            2007050     flatten_7[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 2,210,315\n",
      "Trainable params: 2,210,315\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "d = discriminator(input_shape=(28, 28, 1))\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Generator with Discriminator\n",
    "<img src=\"../images/acgan-2.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam parameters pretrained\n",
    "adam_lr = 0.0002\n",
    "adam_beta_1 = 0.5\n",
    "\n",
    "def ACGAN(latent_size = 100):\n",
    "    # build the discriminator\n",
    "    d_model = discriminator()\n",
    "    d_model.compile(\n",
    "        optimizer=optimizers.Adam(lr=adam_lr, beta_1=adam_beta_1),\n",
    "        loss=['binary_crossentropy', 'sparse_categorical_crossentropy']\n",
    "    )\n",
    "\n",
    "    # build the generator\n",
    "    g_model = generator(latent_size)\n",
    "    g_model.compile(optimizer=optimizers.Adam(lr=adam_lr, beta_1=adam_beta_1),\n",
    "                      loss='binary_crossentropy')\n",
    "\n",
    "    # Inputs\n",
    "    latent = layers.Input(shape=(latent_size, ), name='latent_noise')\n",
    "    image_class = layers.Input(shape=(1,), dtype='int32', name='image_class')\n",
    "\n",
    "    # Get a fake image\n",
    "    fake_img = g_model([latent, image_class])\n",
    "\n",
    "    # Only train generator in combined model\n",
    "    d_model.trainable = False\n",
    "    fake_or_real, label = d_model(fake_img)\n",
    "    acgan = models.Model(inputs=[latent, image_class],\n",
    "                            outputs=[fake_or_real, label],\n",
    "                            name='ACGAN')\n",
    "\n",
    "    acgan.compile(\n",
    "        optimizer=optimizers.Adam(lr=adam_lr, beta_1=adam_beta_1),\n",
    "        loss=['binary_crossentropy', 'sparse_categorical_crossentropy']\n",
    "    )\n",
    "    \n",
    "    return acgan, g_model, d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "latent_noise (InputLayer)        (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "image_class (InputLayer)         (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "generator (Model)                (None, 28, 28, 1)     7763433     latent_noise[0][0]               \n",
      "                                                                   image_class[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "discriminator (Model)            [(None, 1), (None, 10 2210315     generator[1][0]                  \n",
      "====================================================================================================\n",
      "Total params: 9,973,748\n",
      "Trainable params: 7,763,433\n",
      "Non-trainable params: 2,210,315\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "acgan,_,_ = ACGAN(latent_size = 100)\n",
    "acgan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to (..., 28, 28, 1)\n",
    "# normalize dataset with range [-1, 1]\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()\n",
    "\n",
    "# normalize and reshape train set\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "\n",
    "# normalize and reshape test set\n",
    "X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "train_size, test_size = X_train.shape[0], X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_noise_and_labels(batch_size, latent_size):\n",
    "\n",
    "    # generate a new batch of noise\n",
    "    noise = np.random.uniform(-1, 1, (batch_size, latent_size))\n",
    "\n",
    "    # sample some labels\n",
    "    sampled_labels = np.random.randint(0, 10, batch_size)\n",
    "\n",
    "    return noise, sampled_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 50\n",
      "\r",
      "  0/600 [..............................] - ETA: 0s"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'd_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-bd740c5c6c10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# train discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mdis_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbinary_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulticlass_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# acgan with 2 tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m### Train Generator ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd_model' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 100\n",
    "\n",
    "train_history = defaultdict(list)\n",
    "test_history = defaultdict(list)\n",
    "\n",
    "latent_size = 100\n",
    "\n",
    "acgan, g_model, d_model = ACGAN(latent_size)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch {} of {}'.format(epoch + 1, epochs))\n",
    "\n",
    "    batches = int(X_train.shape[0] / batch_size)\n",
    "    progress_bar = utils.Progbar(target=batches)\n",
    "\n",
    "    epoch_gen_loss = []\n",
    "    epoch_dis_loss = []\n",
    "    \n",
    "    ############################### batches training start #######################################\n",
    "    \n",
    "    for index in range(batches):\n",
    "        progress_bar.update(index)\n",
    "        \n",
    "        ###############################################################\n",
    "        ######################## Train Discriminator ##################\n",
    "        \n",
    "        # generate noise and labels\n",
    "        noise, sampled_labels = generate_batch_noise_and_labels(batch_size, latent_size)\n",
    "        \n",
    "        # generate a batch of fake images, using the generated labels as a conditioner\n",
    "        generated_images = g_model.predict([noise, sampled_labels.reshape((-1, 1))], verbose=0)\n",
    "        \n",
    "        # get a batch of real images\n",
    "        image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "        label_batch = y_train[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "        # construct discriminator dataset\n",
    "        X = np.concatenate((image_batch, generated_images))\n",
    "        binary_y = np.array([1] * batch_size + [0] * batch_size)\n",
    "        multiclass_y = np.concatenate((label_batch, sampled_labels), axis=0)\n",
    "\n",
    "        # train discriminator\n",
    "        epoch_dis_loss.append(d_model.train_on_batch(X, [binary_y, multiclass_y])) # acgan with 2 tasks\n",
    "        \n",
    "        ##################################################################\n",
    "        ######################### Train Generator ########################\n",
    "        \n",
    "        # generate 2 * batch size here such that we have\n",
    "        # the generator optimize over an identical number of images as the\n",
    "        # discriminator       \n",
    "        noise, sampled_labels = generate_batch_noise_and_labels(2 * batch_size, latent_size)\n",
    "        \n",
    "        # here: np.ones(2 * batch_size) --> \n",
    "        # all label '1' aims to trick discrimintor to think all generated images are all real(which is labeled as '1')\n",
    "        epoch_gen_loss.append(acgan.train_on_batch(\n",
    "            [noise, sampled_labels.reshape((-1, 1))], [np.ones(2 * batch_size), sampled_labels]))\n",
    "    print('\\nTesting for epoch {}:'.format(epoch + 1))\n",
    "    \n",
    "    \n",
    "    ####################################### training end ##################################################\n",
    "    \n",
    "    \n",
    "    ####################################### evaluation start ################################################\n",
    "    \n",
    "    \n",
    "    ################################################################\n",
    "    ##################### Evaluate Discriminator ###################\n",
    "\n",
    "    # generate a new batch of noise\n",
    "    noise, sampled_labels = generate_batch_noise_and_labels(test_size, latent_size)\n",
    "    \n",
    "    # generate images\n",
    "    generated_images = g_model.predict(\n",
    "        [noise, sampled_labels.reshape((-1, 1))], verbose=False)\n",
    "    \n",
    "    # construct discriminator evaluation dataset\n",
    "    X = np.concatenate((X_test, generated_images))\n",
    "    binary_y = np.array([1] * test_size + [0] * test_size)\n",
    "    multiclass_y = np.concatenate((y_test, sampled_labels), axis=0)\n",
    "\n",
    "    # evaluate discriminator\n",
    "    # test loss\n",
    "    discriminator_test_loss = d_model.evaluate(X, [binary_y, multiclass_y], verbose=False)\n",
    "    # train loss\n",
    "    discriminator_train_loss = np.mean(np.array(epoch_dis_loss), axis=0)\n",
    "    \n",
    "    ################################################################\n",
    "    ######################## Evaluate Generator ####################\n",
    "\n",
    "    # make new noise\n",
    "    noise, sampled_labels = generate_batch_noise_and_labels(2 * test_size, latent_size)\n",
    "\n",
    "    # evaluate generator : evaluate([input], [output], ...)\n",
    "    # test loss\n",
    "    generator_test_loss = acgan.evaluate(\n",
    "        [noise, sampled_labels.reshape((-1, 1))],\n",
    "        [np.ones(2 * test_size), sampled_labels], verbose=False)\n",
    "\n",
    "    # train loss\n",
    "    generator_train_loss = np.mean(np.array(epoch_gen_loss), axis=0)\n",
    "    \n",
    "    \n",
    "    ####################################### evaluation end ################################################\n",
    "    \n",
    "    \n",
    "\n",
    "    ###############################################################\n",
    "    #################### Save Losses per Epoch ####################\n",
    "    \n",
    "    \n",
    "    # append train losses\n",
    "    train_history['generator'].append(generator_train_loss)\n",
    "    train_history['discriminator'].append(discriminator_train_loss)\n",
    "\n",
    "    # append test losses\n",
    "    test_history['generator'].append(generator_test_loss)\n",
    "    test_history['discriminator'].append(discriminator_test_loss)\n",
    "    \n",
    "    # save weights every epoch\n",
    "    g_model.save_weights(\n",
    "        '../logs/params_generator_epoch_{0:03d}.hdf5'.format(epoch), True)\n",
    "    d_model.save_weights(\n",
    "        '../logs/params_discriminator_epoch_{0:03d}.hdf5'.format(epoch), True)\n",
    "\n",
    "    \n",
    "################################### epoch pass end ################################################\n",
    "\n",
    "# Save train test loss history\n",
    "pickle.dump({'train': train_history, 'test': test_history},\n",
    "            open('/home/karen/Downloads/data/logs/acgan-history.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pickle.load(open('/home/karen/Downloads/data/logs/acgan-history.pkl'))\n",
    "\n",
    "for p in ['train', 'test']:\n",
    "    for g in ['discriminator', 'generator']:\n",
    "        hist[p][g] = pd.DataFrame(hist[p][g], columns=['loss', 'generation_loss', 'auxiliary_loss'])\n",
    "        plt.plot(hist[p][g]['generation_loss'], label='{} ({})'.format(g, p))\n",
    "\n",
    "# get the NE and show as an equilibrium point\n",
    "plt.hlines(-np.log(0.5), 0, hist[p][g]['generation_loss'].shape[0], label='Nash Equilibrium')\n",
    "plt.legend()\n",
    "plt.title(r'$L_s$ (generation loss) per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(r'$L_s$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in ['discriminator', 'generator']:\n",
    "    for p in ['train', 'test']:\n",
    "        plt.plot(hist[p][g]['auxiliary_loss'], label='{} ({})'.format(g, p))\n",
    "\n",
    "plt.legend()\n",
    "plt.title(r'$L_c$ (classification loss) per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel(r'$L_c$')\n",
    "plt.semilogy()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights from the last epoch\n",
    "gen.load_weights(sorted(glob('/home/karen/Downloads/data/logs/params_generator*'))[-1])\n",
    "\n",
    "# construct batch of noise and labels\n",
    "noise = np.tile(np.random.uniform(-1, 1, (10, latent_size)), (10, 1))\n",
    "sampled_labels = np.array([[i] * 10 for i in range(10)]).reshape(-1, 1)\n",
    "\n",
    "# generate digits\n",
    "generated_images = gen.predict([noise, sampled_labels], verbose=0)\n",
    "\n",
    "# arrange them into a grid and un-normalize the pixels\n",
    "img = (np.concatenate([r.reshape(-1, 28)\n",
    "                       for r in np.split(generated_images, 10)\n",
    "                       ], axis=-1) * 127.5 + 127.5).astype(np.uint8)\n",
    "\n",
    "# plot images\n",
    "plt.imshow(img, cmap='gray')\n",
    "_ = plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
