{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# VGG Paper\n",
    "\n",
    "[_Very Deep Convolutional Networks for Large-Scale Image Recognition_](https://arxiv.org/pdf/1409.1556.pdf) \n",
    "<img src=\"../../images/VGG-paper.png\" width=\"800\">\n",
    "\n",
    "# VGG Result\n",
    "\n",
    "<img src=\"images/VGG-result.png\" width=\"800\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG Architecture (two size “VGG16” and “VGG19”)\n",
    "\n",
    "- extremely homogeneous architecture:\n",
    "    - 3x3 convolutional layers\n",
    "    - 2x2 max pooling\n",
    "    - 2 fully-connected layers\n",
    "    - softmax classifier. \n",
    "\n",
    "\n",
    "<img src=\"images/VGGNet.png\" width=\"500\">\n",
    "\n",
    "## VGG16 Architecture\n",
    "\n",
    "<img src=\"images/vgg16.png\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main Points of the VGG architecture:**\n",
    "\n",
    "- The use of only 3x3 sized filters, which is small compared to previous models that used 11x11 and 7x7 filter size. One of the benefits is a __decrease in the number of parameters__. \n",
    "\n",
    "\n",
    "- __3 conv layers back to back have an effective receptive field of 7x7__\n",
    "\n",
    "\n",
    "- As the spatial size of the input volumes at each layer decrease, the depth of the volumes increase due to the increased number of filters.\n",
    "\n",
    "\n",
    "- __The number of filters doubles after each maxpool layer__. This reinforces the idea of shrinking spatial dimensions, but growing depth.\n",
    "\n",
    "\n",
    "- Works well on both image classification and localization tasks. __Localization is treated as a regression task.__\n",
    "\n",
    "\n",
    "** Down side of VGG architecture:**\n",
    "\n",
    "- it can be slow to train on large dataset because __the number of model parameters is quite large, due to its depth and its large fully-connected layers.__  (Smaller network architectures have been since proposed with comparable performance, such as SqueezeNet.)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
