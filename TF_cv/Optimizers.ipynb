{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Basic Gradient Descent\n",
    "Gradient descent is a way to minimize an objective function $J(\\theta)$ parameterized by a model's parameters $\\theta \\in \\mathbb{R}^d$ **by updating the parameters in the opposite direction of the gradient of the objective function** $\\nabla_\\theta J(\\theta)$ w.r.t. to the parameters. **The learning rate $\\eta$ determines the size of the steps we take to reach a (local) minimum.** In other words, we follow the direction of the slope of the surface created by the objective function downhill until we reach a valley.\n",
    "\n",
    "<img src=\"../../images/grad.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow train module **`tf.train`**\n",
    "\n",
    "    tf.train.GradientDescentOptimizer\n",
    "    tf.train.MomentumOptimizer\n",
    "    tf.train.RMSPropOptimizer\n",
    "    tf.train.AdadeltaOptimizer\n",
    "    tf.train.AdagradOptimizer\n",
    "    tf.train.AdamOptimizer\n",
    "    tf.train.AdagradDAOptimizer\n",
    "    \n",
    "TF-Keras optimizer module **`tf.contrib.keras.optimizers`**\n",
    "\n",
    "    tf_keras.optimizers.SGD\n",
    "    tf_keras.optimizers.Adadelta\n",
    "    tf_keras.optimizers.Adagrad\n",
    "    tf_keras.optimizers.RMSprop\n",
    "    tf_keras.optimizers.Adamax\n",
    "    tf_keras.optimizers.Nadam\n",
    "    tf_keras.optimizers.Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Variants\n",
    "\n",
    "\n",
    "$$\\theta = \\theta - \\eta \\cdot \\nabla_\\theta J( \\theta; x; y)$$\n",
    "\n",
    "- **Batch gradient descent**\n",
    "    - computes the gradient of the cost function to the parameters Î¸ for the entire training dataset.\n",
    "- **Stochastic gradient descent**\n",
    "    - computes a parameter update for each training example x and label y\n",
    "- **Mini-batch gradient descent**\n",
    "    - computes an update for every mini-batch of nn training examples\n",
    "    \n",
    "Mini-batch gradient descent is typically the algorithm of choice\n",
    "\n",
    "1. updates have lower variances than  stochastic gradient descent, the model converges better.\n",
    "2. the dataset doesn't need to fit in memory like for batch gradient descent\n",
    "3. gradient computation step is faster, because\n",
    "    - the batch is smaller\n",
    "    - make use of highly optimized matrix multiplication operation common to state-of-the-art deep learning libraries.\n",
    "    \n",
    "Short Comings of Mini-Batch Gradient Descent\n",
    "\n",
    "<img src=\"images/learning_rates.jpg\" width=\"400\">\n",
    "\n",
    "- **Learning rate magnitude**\n",
    "    - learning rate too large:\n",
    "        - loss function fluctuates around the minimum preventing convergence\n",
    "    - learning rate too small: \n",
    "        - training takes too long to reach convergence\n",
    "\n",
    "- **Challenge of minimizing highly non-convex error functions**\n",
    "    - escaping suboptimal local minima or saddle points (gradients close to zero in most dimensions) can be difficult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model Mini-Batch gradient descent optimizer\n",
    "# Tensorflow optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "\n",
    "# TF-Keras optimzer\n",
    "optimizer = tf_keras.optimizers.SGD(lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum Optimizer\n",
    "\n",
    "<b>SGD tends to oscillate when the loss surface curves much more steeply in one dimension than in another, which are common around local optima.</b>\n",
    "\n",
    "<img src=\"images/momentum.png\" width=\"600\">\n",
    "\n",
    "Momentum : almost always enjoys better converge rates on deep networks. \n",
    "- In a sense the Momentum optimizer gives potential energy to the update step. \n",
    "    - allows the parameter vector to build up velocity in any direction that has **consistent gradient**. Eg: pushing a ball down a hill. The ball accumulates momentum as it rolls downhill, becoming faster and faster on the way.\n",
    "- As a result, we gain faster convergence and reduced oscillation.\n",
    "\n",
    "Update step:\n",
    "\n",
    "$$v_t = \\gamma v_{t-1} + \\eta \\nabla_\\theta J( \\theta)$$\n",
    "$$\\theta = \\theta - v_t$$\n",
    "\n",
    "\n",
    "**The momentum term (friction term) $\\gamma$ is usually set to 0.9 or a similar value.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Momentum Optimizers\n",
    "\n",
    "# Tensorflow optimizer\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=momentum)\n",
    "\n",
    "# TF-Keras optimizer\n",
    "optimizer = tf_keras.optimizers.SGD(lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesterov Accelerated Gradient (NAG) Optimizer\n",
    "\n",
    "Nesterov Momentum is a **slightly different version of the momentum update.** \n",
    "\n",
    "<img src=\"images/nesterov.jpeg\" width=\"800\">\n",
    "\n",
    "Instead of evaluating gradient at the current position (red circle), we know that *our momentum is about to carry us to the tip of the green arrow*. **With Nesterov momentum we therefore instead evaluate the gradient at this \"looked-ahead\" position.**\n",
    "\n",
    "$$v_t = \\gamma v_{t-1} + \\eta \\nabla_\\theta J( \\theta - \\gamma v_{t-1} )$$\n",
    "$$\\theta = \\theta - v_t$$\n",
    "\n",
    "### This anticipatory update prevents us from going too fast (overshooting), which has significantly increased the performance of RNNs on a number of tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nesterov Optimizers\n",
    "\n",
    "# Tensorflow optimizer\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=momentum, use_nesterov=True)\n",
    "\n",
    "# TF-Keras optimizer\n",
    "optimizer = tf_keras.optimizers.SGD(lr=learning_rate, momentum=momentum, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-parameter adaptive learning rate methods\n",
    "\n",
    "So far the optimizers that we've see manipulated the learning rate globally and equally for all parameters. Tuning the learning rates is an expensive process, so there exists other methods that can adaptively tune the learning rates, and even do so per parameter to perform larger or smaller updates depending on their importance. In this section we highlight some common adaptive methods you may encounter in practice.\n",
    "\n",
    "## Adagrad Optimizer\n",
    "\n",
    "In Adagrad the learning rate is normalize by the sum of squared gradients on a per-parameter basis. This adaptive optimizer performes larger updates for infrequent and smaller updates for frequent parameters. For this reason, it is well-suited for dealing with sparse data.\n",
    "\n",
    "Simplified update step:\n",
    "\n",
    "```\n",
    "# Assume the gradient dx and parameter vector x\n",
    "cache += dx**2\n",
    "x += - learning_rate * dx / (np.sqrt(cache) + eps)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adagrad Optimizers\n",
    "\n",
    "# Tensorflow optimizer\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "# TF-keras optimizer\n",
    "optimizer = tf_keras.optimizers.Adagrad(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaDelta and RMSprop\n",
    "\n",
    "AdaDelta and RMSprop are both very similar optimizers that improves on Adagrad by instead normalizing the learning rate with the moving average of squared gradients. This reduces the aggressive, monotonically decreasing learning rate found in Adagrad.\n",
    "\n",
    "Simplified update step:\n",
    "\n",
    "```\n",
    "cache = decay_rate * cache + (1 - decay_rate) * dx**2\n",
    "x += - learning_rate * dx / (np.sqrt(cache) + eps)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adadelta and RMSprop Optimizers\n",
    "\n",
    "# Tensorflow optimizer\n",
    "\n",
    "# Adadelta\n",
    "optimizer = tf.train.AdadeltaOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "# RMSprop\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "# TF-keras optimizer\n",
    "\n",
    "# Adadelta\n",
    "optimizer = tf_keras.optimizers.Adadelta(lr=learning_rate)\n",
    "\n",
    "# RMSprop\n",
    "optimizer = tf_keras.optimizers.RMSprop(lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Moment Estimation (Adam) Optimizer\n",
    "\n",
    "Adam is often the most recommended optimizer for training Deep Neural networks. It combines idea from both RMSProp the Momentum method. It generates a \"smooth\" estimate (exponentially decaying average) of the gradients' mean and variance. Giving you the best a less noisy gradient and an adaptive learning rates for each parameter.\n",
    "\n",
    "Simplified update step:\n",
    "\n",
    "```\n",
    "m = beta1*m + (1-beta1)*dx\n",
    "v = beta2*v + (1-beta2)*(dx**2)\n",
    "x += - learning_rate * m / (np.sqrt(v) + eps)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Different Optimizers\n",
    "\n",
    "<img src=\"../../images/opt1.gif\" width=\"400\" align=\"left\">\n",
    "<img src=\"../../images/opt2.gif\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are other Tensorflow optimizers:\n",
    "\n",
    "    tf.train.AdagradDAOptimizer\n",
    "    tf_keras.optimizers.Adamax\n",
    "    tf_keras.optimizers.Nadam\n",
    "    \n",
    "I will leave it to you to explore these optimizers on your own time.\n",
    "\n",
    "## Next Lesson\n",
    "### CNN in Tensorflow and TF-Keras\n",
    "-  You will learn about CNN layers and how they work\n",
    "\n",
    "<img src=\"../../images/divider.png\" width=\"100\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
